{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.munge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from snkrfinder.imports import *\n",
    "from snkrfinder.core import *\n",
    "\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "### might be fastai wrappers to do this elegantly... (untar_data?)\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snkrfinder.data.munge\n",
    "\n",
    "### version 1.0 Dec 2020 (refactor using pytorch/nbdev/fastai framework)\n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "This is a project initiated while an Insight Data Science fellow.  It grew out of thinking about how to make data-driven tools that could impact the fashion industry which I had been working working in.   The original over-scoped idea was to make a shoe desighn tool which could quickly develop some sneaker designs based on choosing some examples, and some text descriptors.  Designs are constrained by the \"latent space\" defined (discovered?) by a database of shoe images.  However, given the 3 week sprint allowed for development, I pared the tool down to a simple \"aesthetic\" recommender for sneakers, using the same idea of utilizing an embedding space defined by the database fo shoe images.\n",
    "\n",
    "NOTE:  symbolic link in the nbs directory to enable the module loads in these notebooks.  i.e. `ln -s ../snkrfinder/ snkrfinder`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a cool reference for a fastai VAE\n",
    "https://medium.com/@dhuynh95/an-introduction-to-unsupervised-learning-with-fastai-a6dbd78eca2b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get a database of sneaker images.   The sneaker images are only 136 pixels wide, and organized by 'Category', 'SubCategory', and 'Brand'.   Additional semantic information is also available from Mechanical Turk labeling, and is available packed into matlab files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ergonyc/Projects/Project2.0/snkrfinder/nbs\n",
      "/home/ergonyc/Projects/Project2.0/snkrfinder\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "print(Path().cwd())\n",
    "os.chdir(L_ROOT)\n",
    "print(Path().cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: DATA\n",
    "\n",
    "### Part 1: import the UT-Zappos50k database\n",
    "\n",
    "Using fastai `untar_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_zappos_db():\n",
    "    \"import the UT zappos 50k database from vision.cs.utexas.edu\"\n",
    "    # the images are wider than tall with the product already taking up aproximately the whole vertical dimension\n",
    "    url_images = \"http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images.zip\"\n",
    "    url_meta = \"http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-data.zip\"\n",
    "\n",
    "    DATA_path = D_ROOT\n",
    "    meta_path = untar_data(url_meta, dest=DATA_path)\n",
    "    im_path = untar_data(url_images,dest=DATA_path)\n",
    "    \n",
    "    return meta_path, im_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set cleaning\n",
    "\n",
    "The dataset is very diverse and not constructed in order to think about how popular footwear is aesthetically related.  I'm simplifying the database to include 4 categories which seem to split aesthetics for general footwear:\n",
    "\n",
    "1) BOOTS - weatherized and/or protected footwear for work or outdoor activity\n",
    "2) SANDALS - charachterized by a sole and straps\n",
    "3) SHOES - generic non \"boot\" footwear.  includes heels and formalwear\n",
    "4) SNEAKERS - atheletic / comfort inspired "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_zappos_meta(path_meta):\n",
    "    \"read the metadat from UT zappos 50k db\"\n",
    "\n",
    "    def _path_from_mat(fname):\n",
    "        \"\"\" reads zappos imagepath from matlab file\"\"\"\n",
    "        data = sio.loadmat(fname)['imagepath']\n",
    "        return [i[0][0] for i in data]\n",
    "\n",
    "    image_path = _path_from_mat(path_meta/'image-path.mat')\n",
    "    df = pd.read_csv(path_meta/'meta-data.csv')\n",
    "\n",
    "    df[\"path\"]=image_path\n",
    "    \n",
    "    # ad sub-categories (one-hot)\n",
    "    categories=pd.read_csv(path_meta/'meta-data-bin.csv')\n",
    "    df = pd.merge(df, categories,  how='left', on='CID')# left_on=['CID'], right_on = ['CID'])\n",
    "\n",
    "\n",
    "    # fix the path by remove trailing periods in folder names\n",
    "    df.loc[df.path.str.contains(\"./\",regex=False),\"path\"] = [i.replace(\"./\",\"/\") for i in df.loc[df.path.str.contains(\"./\",regex=False),\"path\"]]\n",
    "    df.loc[df.path.str.contains(\"Levi\\'s \",regex=False),\"path\"] = [i.replace(\"Levi\\'s \",\"Levis \") for i in df.loc[df.path.str.contains(\"Levi\\'s \",regex=False),\"path\"]]\n",
    "    # create brands and category stubs...\n",
    "    df['path_and_file'] = df.path.apply(lambda path: (os.path.normpath(path)).split(os.sep) ) \n",
    "    df_to_add = pd.DataFrame(df['path_and_file'].tolist(), columns=['Category1','Category2','Brand','Filename'])\n",
    "\n",
    "    df = df.merge(df_to_add, left_index=True, right_index=True)\n",
    "    #df = pd.merge(df, df_to_add, left_index=True, right_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path, im_path = get_zappos_db()\n",
    "\n",
    "assert (meta_path==ZAPPOS_META_DIR)\n",
    "assert(im_path==D_ROOT/DBS[\"zappos\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_zappos_meta(meta_path)\n",
    "\n",
    "assert (df['Category'] == df['Category1']).all()\n",
    "assert (df['SubCategory'] == df['Category2']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplify:\n",
    "\n",
    "Categories:\n",
    "    1. SHOES, \n",
    "    2. BOOTS, \n",
    "    3. \"SNEAKERS\", and \n",
    "    4. \"SLIPPERS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[ TODO:  change the bullets to a short paragraph describing the simplificaiton ]]\n",
    "\n",
    "Only include \"adult\" shoes\n",
    "    - Adult = mens + womens (kids = not adults),+ etc (unisex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct these from the Zappos I needed to pull sneakers from shoes and exclude some sub-categories.  e.g. tall boots which would drive the representation of boots.\n",
    "\n",
    "    BOOTS:\n",
    "      BOOTS\n",
    "        - ankle,  mid-calf\n",
    "        - exclude: knee high , over the knee , prewalker\n",
    "\n",
    "    SANDALS:\n",
    "      SANDALS\n",
    "        - athletic, flat\n",
    "        - exclude: heels \n",
    "        \n",
    "    SHOES:\n",
    "      SHOES\n",
    "        - Boat shoes, clogs and mules,  flats,  loafers, oxfords, prewalker\n",
    "        - exclude: heels , crib shoes , firstwalker (exclude)\n",
    "\n",
    "    SNEAKERS\n",
    "       SHOES\n",
    "       - sneakers and athletic shoes\n",
    "\n",
    "     SLIPPERS (exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def simplify_zappos_db(df):\n",
    "    \" simplifies the db (df)\"\n",
    "    # add our \"sneaker category\"\n",
    "    df.loc[:,'Sneakers'] = (df['Category2'] == 'Sneakers and Athletic Shoes')\n",
    "\n",
    "    # refine boot\n",
    "    df.loc[:,'Boots'] = (  (df.Category1 == 'Boots') \n",
    "                         & (df.Category2 != 'Knee High')\n",
    "                         & (df.Category2 != 'Over the Knee')\n",
    "                         & (df.Category2 != 'Prewalker Boots') )\n",
    "\n",
    "    # refine shoes\n",
    "    df.loc[:,'Shoes'] = (  (df.Category1 == 'Shoes') \n",
    "                         & (df.Category2 != 'Sneakers and Athletic Shoes')\n",
    "                         & (df.Category2 != 'Heels')                         \n",
    "                         & (df.Category2 != 'Crib Shoes')\n",
    "                         & (df.Category2 != 'Firstwalker')\n",
    "                         & (df.Category2 != 'Prewalker') )\n",
    "\n",
    "    # refine shoes\n",
    "    df.loc[:,'Slippers'] = (  (df.Category1 == 'Slippers')\n",
    "                         & (df.Category2 != 'Boot') )\n",
    "\n",
    "\n",
    "    ############\n",
    "    #remove ([ 'Boys',  'Boys;Girls', 'Girls','Women;Girls', nan\n",
    "\n",
    "    mens =  df['Gender'] == 'Men'       \n",
    "    womens =  df['Gender'] == 'Women' \n",
    "    etc =  df['Gender'].str.contains('Men;', na=False)\n",
    "\n",
    "    df.loc[:,'Adult'] = mens | womens | etc\n",
    "\n",
    "    df.loc[:,'Mens'] = mens \n",
    "    df.loc[:,'Womens'] = womens\n",
    "\n",
    "    df.loc[:,'OGcategory'] = df.Category\n",
    "    df.loc[:,'Category'] = pd.NA\n",
    "\n",
    "    df.loc[(df.Shoes==1),'Category'] = 'Shoes'\n",
    "    df.loc[(df.Boots==1),'Category'] = 'Boots'\n",
    "    df.loc[(df.Sneakers==1),'Category'] = 'Sneakers'\n",
    "    df.loc[(df.Slippers==1),'Category'] = 'Slippers'\n",
    "\n",
    "    \n",
    "    # make some expository columns \n",
    "    keep_columns = ['CID','Category',\n",
    "                     'path','path_and_file',\n",
    "                     'Category1', 'Category2','OGcategory'\n",
    "                     'Brand','Filename',\n",
    "                     'Sneakers','Boots',\n",
    "                     'Shoes', 'Slippers','Adult',\n",
    "                     'Gender']\n",
    "\n",
    "    df = df.filter(items=keep_columns)\n",
    "    #keep Adult, Sneakers, Boots, Shoes, Slippers\n",
    "    keep_rows = (df.Sneakers | df.Boots | df.Shoes| df.Slippers) & (df.Adult)\n",
    "    #Only keep Adult (men+women) and Sneakers, Boots, Shoes\n",
    "    df = df[keep_rows.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shoes', 'Boots', 'Sandals', 'Slippers'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "df.Category.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = simplify_zappos_db(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Category</th>\n",
       "      <th>path</th>\n",
       "      <th>path_and_file</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Sneakers</th>\n",
       "      <th>Boots</th>\n",
       "      <th>Shoes</th>\n",
       "      <th>Slippers</th>\n",
       "      <th>Adult</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100627-72</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100627.72.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100627.72.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100627.72.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100627-255</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100627.255.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100627.255.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100627.255.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100657-72</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100657.72.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100657.72.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100657.72.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100657-216</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100657.216.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100657.216.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100657.216.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101026-3</td>\n",
       "      <td>Boots</td>\n",
       "      <td>Boots/Mid-Calf/Durango/101026.3.jpg</td>\n",
       "      <td>[Boots, Mid-Calf, Durango, 101026.3.jpg]</td>\n",
       "      <td>Boots</td>\n",
       "      <td>Mid-Calf</td>\n",
       "      <td>101026.3.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CID Category                                    path  \\\n",
       "0   100627-72    Shoes   Shoes/Oxfords/Bostonian/100627.72.jpg   \n",
       "1  100627-255    Shoes  Shoes/Oxfords/Bostonian/100627.255.jpg   \n",
       "2   100657-72    Shoes   Shoes/Oxfords/Bostonian/100657.72.jpg   \n",
       "3  100657-216    Shoes  Shoes/Oxfords/Bostonian/100657.216.jpg   \n",
       "4    101026-3    Boots     Boots/Mid-Calf/Durango/101026.3.jpg   \n",
       "\n",
       "                                 path_and_file Category1 Category2  \\\n",
       "0   [Shoes, Oxfords, Bostonian, 100627.72.jpg]     Shoes   Oxfords   \n",
       "1  [Shoes, Oxfords, Bostonian, 100627.255.jpg]     Shoes   Oxfords   \n",
       "2   [Shoes, Oxfords, Bostonian, 100657.72.jpg]     Shoes   Oxfords   \n",
       "3  [Shoes, Oxfords, Bostonian, 100657.216.jpg]     Shoes   Oxfords   \n",
       "4     [Boots, Mid-Calf, Durango, 101026.3.jpg]     Boots  Mid-Calf   \n",
       "\n",
       "         Filename  Sneakers  Boots  Shoes  Slippers  Adult Gender  \n",
       "0   100627.72.jpg     False  False   True     False   True    Men  \n",
       "1  100627.255.jpg     False  False   True     False   True    Men  \n",
       "2   100657.72.jpg     False  False   True     False   True    Men  \n",
       "3  100657.216.jpg     False  False   True     False   True    Men  \n",
       "4    101026.3.jpg     False   True  False     False   True    Men  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the simplified dataframe for further analysis\n",
    "\n",
    "\n",
    "Also use sklearn `train_test_split` to create category stratified train/test/validate groups.  We'll keep 15 percent of our data to truly test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27614, 13)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def skl_tt_split(df,strat_cat):\n",
    "    \"adds stratified train-validate-test via sklearn\"\n",
    "\n",
    "\n",
    "    X = df.index\n",
    "    y = strat_cat\n",
    "\n",
    "    train_ratio = 0.70\n",
    "    validation_ratio = 0.15\n",
    "\n",
    "    # keep\n",
    "    test_ratio = 0.15\n",
    "\n",
    "    # train is now 75% of the entire data set\n",
    "    # the _junk suffix means that we drop that variable completely\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio,stratify=y, random_state=666)\n",
    "\n",
    "    # test is now 10% of the initial data set\n",
    "    # validation is now 15% of the initial data set\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio),stratify=y_test, random_state=666) \n",
    "    # pack into the dataframe\n",
    "    df.loc[:,'train'] = False\n",
    "    df.loc[:,'test'] = False\n",
    "    df.loc[:,'validate'] = False\n",
    "    df.loc[:,'t_t_v'] = 'train'\n",
    "    df.loc[x_train,'train'] = True\n",
    "    df.loc[x_test,'test'] = True\n",
    "    df.loc[x_val,'validate'] = True\n",
    "    df.loc[x_test,'t_t_v'] = 'test'\n",
    "    df.loc[x_val,'t_t_v'] = 'valid'\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>Category</th>\n",
       "      <th>path</th>\n",
       "      <th>path_and_file</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Sneakers</th>\n",
       "      <th>Boots</th>\n",
       "      <th>Shoes</th>\n",
       "      <th>Slippers</th>\n",
       "      <th>Adult</th>\n",
       "      <th>Gender</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>validate</th>\n",
       "      <th>t_t_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100627-72</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100627.72.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100627.72.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100627.72.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100627-255</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100627.255.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100627.255.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100627.255.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100657-72</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100657.72.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100657.72.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100657.72.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100657-216</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Shoes/Oxfords/Bostonian/100657.216.jpg</td>\n",
       "      <td>[Shoes, Oxfords, Bostonian, 100657.216.jpg]</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>100657.216.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101026-3</td>\n",
       "      <td>Boots</td>\n",
       "      <td>Boots/Mid-Calf/Durango/101026.3.jpg</td>\n",
       "      <td>[Boots, Mid-Calf, Durango, 101026.3.jpg]</td>\n",
       "      <td>Boots</td>\n",
       "      <td>Mid-Calf</td>\n",
       "      <td>101026.3.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Men</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CID Category                                    path  \\\n",
       "0   100627-72    Shoes   Shoes/Oxfords/Bostonian/100627.72.jpg   \n",
       "1  100627-255    Shoes  Shoes/Oxfords/Bostonian/100627.255.jpg   \n",
       "2   100657-72    Shoes   Shoes/Oxfords/Bostonian/100657.72.jpg   \n",
       "3  100657-216    Shoes  Shoes/Oxfords/Bostonian/100657.216.jpg   \n",
       "4    101026-3    Boots     Boots/Mid-Calf/Durango/101026.3.jpg   \n",
       "\n",
       "                                 path_and_file Category1 Category2  \\\n",
       "0   [Shoes, Oxfords, Bostonian, 100627.72.jpg]     Shoes   Oxfords   \n",
       "1  [Shoes, Oxfords, Bostonian, 100627.255.jpg]     Shoes   Oxfords   \n",
       "2   [Shoes, Oxfords, Bostonian, 100657.72.jpg]     Shoes   Oxfords   \n",
       "3  [Shoes, Oxfords, Bostonian, 100657.216.jpg]     Shoes   Oxfords   \n",
       "4     [Boots, Mid-Calf, Durango, 101026.3.jpg]     Boots  Mid-Calf   \n",
       "\n",
       "         Filename  Sneakers  Boots  Shoes  Slippers  Adult Gender  train  \\\n",
       "0   100627.72.jpg     False  False   True     False   True    Men   True   \n",
       "1  100627.255.jpg     False  False   True     False   True    Men  False   \n",
       "2   100657.72.jpg     False  False   True     False   True    Men   True   \n",
       "3  100657.216.jpg     False  False   True     False   True    Men   True   \n",
       "4    101026.3.jpg     False   True  False     False   True    Men   True   \n",
       "\n",
       "    test  validate  t_t_v  \n",
       "0  False     False  train  \n",
       "1   True     False   test  \n",
       "2  False     False  train  \n",
       "3  False     False  train  \n",
       "4  False     False  train  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "df = skl_tt_split(df,df.Category)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save it\n",
    "filename = \"zappos-50k-simplified\"\n",
    "#df.to_csv(f\"data/{filename}.csv\")\n",
    "df.to_pickle(f\"data/{filename}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "df2 = df.sort_values('path', ascending=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "#df4_[[\"CID\",\"path\",\"classes\"]].head(5)\n",
    "\n",
    "filename = \"zappos-50k-simplified_sort\"\n",
    "#df.to_csv(f\"data/{filename}.csv\")\n",
    "df2.to_pickle(f\"data/{filename}.pkl\")\n",
    "df2.to_json(f\"data/{filename}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unpickle the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = \"zappos-50k-simplified_sort\"\n",
    "df = pd.read_pickle(f\"data/{filename}.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a unfied database of \"sneakers\"\n",
    "\n",
    "- images (need to access) path to fit beta-VAE \n",
    "- descriptions for fitting text autoencoder\n",
    "- skip \"meta\" data (will come back to this later for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ZAPPOS_DF_SIMPLIFIED #\"zappos-50k-simplified_sort\"\n",
    "df_zappos = pd.read_pickle(f\"data/{filename}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/ergonyc/Projects/DATABASE/SnkrScrpr/data/full_data')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRAPED_META_DIR/SCRAPED_DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>hero_fullpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.goat.com/sneakers/air-jordan-11-retro-bred-2012-378037-010</td>\n",
       "      <td>/Users/ergonyc/Projects/DATABASE/SnkrScrpr/data/goat/img/99543f4630.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.goat.com/sneakers/yeezy-boost-700-carbon-blue-yzy-700-what-the</td>\n",
       "      <td>/Users/ergonyc/Projects/DATABASE/SnkrScrpr/data/goat/img/3fbd48e729.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          url  \\\n",
       "0      https://www.goat.com/sneakers/air-jordan-11-retro-bred-2012-378037-010   \n",
       "1  https://www.goat.com/sneakers/yeezy-boost-700-carbon-blue-yzy-700-what-the   \n",
       "\n",
       "                                                             hero_fullpath  \n",
       "0  /Users/ergonyc/Projects/DATABASE/SnkrScrpr/data/goat/img/99543f4630.jpg  \n",
       "1  /Users/ergonyc/Projects/DATABASE/SnkrScrpr/data/goat/img/3fbd48e729.jpg  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scraped = pd.read_pickle(f\"{SCRAPED_META_DIR/SCRAPED_DF}.pkl\")\n",
    "\n",
    "# load into pandas\n",
    "attributes = df_scraped.attributes.values\n",
    "description = df_scraped.description.values\n",
    "df_scraped[['url','hero_fullpath']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to put the scraped databases from SNS (sneakersnstuff.com) and GOAT (goat.com) into a dataframe with columns suitable merge with the UTZappos database I originally started with.   \n",
    "I'll spend some time infering the `Category`, `Brand`, `Gender` (and `model`?) so I can pay attention to class balance .  From the transfer learning work, the `Slippers` category is pretty poor, but I should be able to use that net to label the scraped data... and validate based on the `attributes` and `see_also` fields.\n",
    "\n",
    "First things first:  fix the \"hero_fullpath\" so its agnostic of OS (Mac or Linux).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    scraped/goat/99543f4630.jpg\n",
       " 1    scraped/goat/3fbd48e729.jpg\n",
       " 2    scraped/goat/6721456f62.jpg\n",
       " 3    scraped/goat/27fbbaad00.jpg\n",
       " 4    scraped/goat/df16a19226.jpg\n",
       " Name: path, dtype: object,\n",
       " 1333    scraped/sns/eb4f3eada8.jpg\n",
       " 1334    scraped/sns/5dace85f70.jpg\n",
       " 1335    scraped/sns/2a18731113.jpg\n",
       " 1336    scraped/sns/9cb275f3aa.jpg\n",
       " 1337    scraped/sns/6d6c0b7b97.jpg\n",
       " Name: path, dtype: object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cooresponds to the relative path in DBS_REL['goat'] and DBS_REL['sns']\n",
    "df_scraped.loc[:,\"path\"]=df_scraped.hero_fullpath.str.split('/').apply(lambda x: 'scraped/'+x[-3]+'/'+x[-1])\n",
    "df_scraped[\"path\"].head(),df_scraped[\"path\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_cat(lst):\n",
    "    for l in lst:\n",
    "        if l.startswith(\"CATEGORY\"):\n",
    "            return l.split(\"\\n\")[-1]\n",
    "    return \"na\" #np.nan\n",
    "\n",
    "def extract_brand_goat(lst):\n",
    "    for l in lst:\n",
    "        if l.startswith(\"BRAND\"):\n",
    "            return l.split(\"\\n\")[-1]\n",
    "    return \"na\"\n",
    "\n",
    "def extract_brand_sns(lst):\n",
    "    return lst[1]\n",
    "\n",
    "def extract_db_nm(pathn):\n",
    "    return pathn.split('/')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.loc[:,\"brand\"]=df_scraped.attributes.apply(extract_brand_sns)\n",
    "df_scraped.loc[:,\"cat\"]=df_scraped.attributes.apply(extract_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goat'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_scraped[\"attributes\"].values[-5]\n",
    "df_scraped[\"path\"].values[0].split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.loc[:,\"db_name\"]=df_scraped[\"path\"].apply(extract_db_nm)\n",
    "\n",
    "df_scraped.loc[df_scraped['db_name']=='goat',\"brand\"]=df_scraped.loc[df_scraped['db_name']=='goat',\"attributes\"].apply(extract_brand_goat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped_og = df_scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to wrap the above proceedure into a little function for exporting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_scraped_db():\n",
    "    \"collect meta data fromscraped databases\"\n",
    "    \n",
    "    def _extract_cat(lst):\n",
    "        for l in lst:\n",
    "            if l.startswith(\"CATEGORY\"):\n",
    "                return l.split(\"\\n\")[-1]\n",
    "        return \"na\" #np.nan\n",
    "\n",
    "    def _extract_brand_goat(lst):\n",
    "        for l in lst:\n",
    "            if l.startswith(\"BRAND\"):\n",
    "                return l.split(\"\\n\")[-1]\n",
    "        return \"na\"\n",
    "\n",
    "    def _extract_brand_sns(lst):\n",
    "        return lst[1]\n",
    "\n",
    "    def _extract_db_nm(pathn):\n",
    "        return pathn.split('/')[0]\n",
    "    \n",
    "    df_scraped = pd.read_pickle(f\"{SCRAPED_META_DIR/SCRAPED_DF}.pkl\")\n",
    "    df_scraped.loc[:,\"path\"]=df_scraped.hero_fullpath.str.split('/').apply(lambda x: 'scraped/'+x[-3]+'/'+x[-1])\n",
    "    df_scraped.loc[:,\"brand\"]=df_scraped.attributes.apply(_extract_brand_sns)\n",
    "    df_scraped.loc[:,\"cat\"]=df_scraped.attributes.apply(_extract_cat)\n",
    "    df_scraped.loc[:,\"db_name\"]=df_scraped[\"path\"].apply(_extract_db_nm)\n",
    "    df_scraped.loc[df_scraped['db_name']=='goat',\"brand\"]=df_scraped.loc[df_scraped['db_name']=='goat',\"attributes\"].apply(_extract_brand_goat)\n",
    "    return df_scraped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def merge_dbs(df_zappos,df_scraped):\n",
    "    \"could be any dfs with 'path','train','test','validate','t_t_v'\"\n",
    "    # TODO:  add \"is_valid\" wiich is test and (so validate are part of test)?)\n",
    "    return pd.merge(df_zappos,df_scraped,how='outer',on=['path','train','test','validate','t_t_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_scraped_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify across db_name\n",
    "# skl_tt_split defined in data.zappos\n",
    "df_scraped = skl_tt_split(df,df.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "27609    False\n",
       "27610    False\n",
       "27611    False\n",
       "27612    False\n",
       "27613    False\n",
       "Name: Sneakers, Length: 27614, dtype: bool"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zappos['Sneakers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def extract_zap_sneakers(df_zappos):\n",
    "    return df_zappos[df_zappos['Sneakers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9434, 17)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zap = extract_zap_sneakers(df_zappos)\n",
    "df_zap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2337, 17), (27614, 17), (11771, 29))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = merge_dbs(df_zap,df_scraped)\n",
    "\n",
    "df_scraped.columns,df_zappos.columns,df_test.columns\n",
    "\n",
    "df_scraped.shape,df_zappos.shape,df_test.shape\n",
    "\n",
    "# TODO:  check for duplicate paths before saving..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the combined db for easy access later.\n",
    "df_test.to_pickle(os.path.join(\"data\", f\"{COMBINED_DF}.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01a_data.munge.ipynb.\n",
      "Converted 01b_data.load.ipynb.\n",
      "Converted 02a_model.core.ipynb.\n",
      "Converted 02b_model.transfer.ipynb.\n",
      "Converted 02c_model.cvae.ipynb.\n",
      "Converted 04a_widgets.feats.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
