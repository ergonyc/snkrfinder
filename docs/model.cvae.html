---

title: first snkrfinder.model.cvae

keywords: fastai
sidebar: home_sidebar



nb_path: "nbs/02c_model.cvae.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02c_model.cvae.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="OVERVIEW:-cvae-module---convolutional-variational-auto-encoder">OVERVIEW: cvae module - convolutional variational auto encoder<a class="anchor-link" href="#OVERVIEW:-cvae-module---convolutional-variational-auto-encoder"> </a></h2><blockquote><p>TODO:clean up this preamble section
preamble: This is a project initiated while an Insight Data Science fellow.  It grew out of my interest in making data driven tools in the fashion/retail space I had most recently been working.   The original over-scoped idea was to make a shoe desighn tool which could quickly develop some initial sneakers based on choosing some examples, and some text descriptors.  Designs are constrained by the "latent space" defined (discovered?) by a database of shoe images.  However, given the 3 week sprint allowed for development, I pared the tool down to a simple "aesthetic" recommender for sneakers, using the same idea of utilizing an embedding space defined by the database fo shoe images.</p>
</blockquote>
<p>Most of the code is derived from the work of @EtieeneT. (e.g.: TabularData <a href="https://github.com/EtienneT/TabularVAE">https://github.com/EtienneT/TabularVAE</a> and later <a href="https://github.com/EtienneT/vae">https://github.com/EtienneT/vae</a> )</p>
<h3 id="sneaker-image-encoding-via-various-flavors-of-auto-encoder.">sneaker image encoding via various flavors of auto-encoder.<a class="anchor-link" href="#sneaker-image-encoding-via-various-flavors-of-auto-encoder."> </a></h3><ul>
<li><p>Auto Encoder: AE</p>
<ul>
<li><del>linear encoder / decoder</del></li>
<li><p>convolutional encoder / decoder</p>
<ul>
<li><p>encoders</p>
<ul>
<li>pretrained (e.g. resnet, mobilenet_v2)</li>
<li>'vanilla' convolutional</li>
<li>'vanilla' ResBlock</li>
</ul>
</li>
<li><p>decoders</p>
<ul>
<li>'vanilla' convolutional</li>
<li>'vanilla' ResBlock</li>
</ul>
</li>
</ul>
</li>
<li>Linear Latent representation (<a href="/snkrfinder/model.cvae#LatentLayer"><code>LatentLayer</code></a>)</li>
</ul>
</li>
<li><p>Variational- Auto Encoder:  VAE or ùú∑-VAE</p>
<ul>
<li>Variational "bottleneck": "reparameterazation trick" for two variable linear latents<ul>
<li>ùú∑-VAE: by increasing the relative strenght of error signal of the KLD through a beta variational parameter we can get better formed latent spaces which are somewhat "disentangled". That is have some semantic or meaningful structure in the representation. </li>
</ul>
</li>
<li>MMD- variational autoencoder uses a Linear Latent and MMD as the retularizer<ul>
<li>The KLD has some problems and "over-regularizes" or simply isn't strong enough compared to the Maximum Mean Discrepancy (MMD) loss and tends to converge to a somewhat degenerate solution</li>
<li>MD regularization of the latent space has great advantage but at a computational expense</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="FUTURE-EXTENSIONS:">FUTURE EXTENSIONS:<a class="anchor-link" href="#FUTURE-EXTENSIONS:"> </a></h3>
<pre><code>-  model based data cleaning (widget module?)
- GAN finetuning?
- crappify general pattern
- throw out based on inspection of high loss
- try mixed labels?  things that are &gt;50% sneakers included???


</code></pre>
<h3 id="TODO:-fix-loss-/-metrics-reduction-logic">TODO: fix loss / metrics reduction logic<a class="anchor-link" href="#TODO:-fix-loss-/-metrics-reduction-logic"> </a></h3><p>batchmean should <em>only</em> apply to KLD because the mean over latents in not meaningful.
'none', 'mean', 'sum' for reduction over "batches"</p>
<p>all the other <em>scaling</em> should come through alpha....</p>
<h3 id="TODO:-find-bugs-in-github-actions">TODO: find bugs in github actions<a class="anchor-link" href="#TODO:-find-bugs-in-github-actions"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using--fastai-V2:-data-pipelining">Using  fastai V2: data pipelining<a class="anchor-link" href="#Using--fastai-V2:-data-pipelining"> </a></h2><ul>
<li>Datablock API</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Load the saved merged database, and set the seeds.  And doublecheck our data is where we expect.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="prep_df_for_datablocks" class="doc_header"><code>prep_df_for_datablocks</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L27" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>prep_df_for_datablocks</code>(<strong><code>df</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">prep_df_for_datablocks</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_ae_btfms" class="doc_header"><code>get_ae_btfms</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L41" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_ae_btfms</code>(<strong><code>stats</code></strong>=<em><code>'sneaker'</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_ae_no_aug" class="doc_header"><code>get_ae_no_aug</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L65" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_ae_no_aug</code>(<strong><code>stats</code></strong>=<em><code>'sneaker'</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="FastAI-&quot;block&quot;-for-autoencoder">FastAI "block" for autoencoder<a class="anchor-link" href="#FastAI-&quot;block&quot;-for-autoencoder"> </a></h2><p>Next we need our own version of ReadTabBatch that will return our inputs</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TensorPoint" class="doc_header"><code>class</code> <code>TensorPoint</code><a href="https://github.com/fastai/fastai/tree/master/fastai/vision/core.py#L144" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TensorPoint</code>(<strong><code>x</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>TensorBase</code></p>
</blockquote>
<p>Basic type for points in an image</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Tensor2Vect" class="doc_header"><code>class</code> <code>Tensor2Vect</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L89" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Tensor2Vect</code>(<strong><code>x</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/snkrfinder/model.cvae#TensorPoint"><code>TensorPoint</code></a></p>
</blockquote>
<p>Basic type for points in an image</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LatentsTensor" class="doc_header"><code>class</code> <code>LatentsTensor</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L93" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LatentsTensor</code>(<strong><code>x</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/snkrfinder/model.cvae#Tensor2Vect"><code>Tensor2Vect</code></a></p>
</blockquote>
<p>Basic type for latents as Tensor inheriting from TensorPoint (vectors)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="df_get_x" class="doc_header"><code>df_get_x</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L141" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>df_get_x</code>(<strong><code>r</code></strong>)</p>
</blockquote>
<p>datablock df helper for VAE Block using <code>LatentTuple</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="df_get_y" class="doc_header"><code>df_get_y</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L145" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>df_get_y</code>(<strong><code>r</code></strong>)</p>
</blockquote>
<p>datablock df helper for VAE Block using <code>LatentTuple</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LatentsTensorBlock" class="doc_header"><code>LatentsTensorBlock</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L152" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LatentsTensorBlock</code>()</p>
</blockquote>
<p>Class wrapper for the AE <code>LatentTensor</code> Block</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="df_ae_x" class="doc_header"><code>df_ae_x</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L157" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>df_ae_x</code>(<strong><code>r</code></strong>, <strong><code>im_path</code></strong>=<em><code>Path('/home/ergonyc/Projects/Project2.0/snkrfinder/data')</code></em>)</p>
</blockquote>
<p>Autoencoder LatentsTensorBlock datablock df helper</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="df_ae_y" class="doc_header"><code>df_ae_y</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L164" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>df_ae_y</code>(<strong><code>r</code></strong>)</p>
</blockquote>
<p>The target is the same as the input for AE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="LatentTupleBlock" class="doc_header"><code>LatentTupleBlock</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L175" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>LatentTupleBlock</code>()</p>
</blockquote>
<p>Class wrapper for the AE <code>LatentTuple</code> Block (depricated)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Don't forget to set  <code>n_inp=1</code>. Otherwise the default to make the  input to 1-len(blocks).  Also note that the <a href="/snkrfinder/model.core#FeatsResize"><code>FeatsResize</code></a> is used to avoid the random jittering from resize during training.  Only the very narrow batch augmentations will be used.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_ae_DataBlock" class="doc_header"><code>get_ae_DataBlock</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L184" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_ae_DataBlock</code>(<strong><code>aug</code></strong>=<em><code>True</code></em>, <strong><code>im_path</code></strong>=<em><code>Path('/home/ergonyc/Projects/Project2.0/snkrfinder/data')</code></em>, <strong><code>stats</code></strong>=<em><code>'sneaker'</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>)</p>
</blockquote>
<p>wrapper to get the standard AE datablock with <code>ImageBlock</code>,<code>LatentTensor</code> target</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="creating-the-VAE">creating the VAE<a class="anchor-link" href="#creating-the-VAE"> </a></h2><p>Variational Auto-Encoder for fastai</p>
<p>I'm going to use a generic convolutional net as the basis of the encoder, and its reverse as the decoder. This is a proof of concept for using the <em>fastai</em> framework, and will experiment with pre-trained resnet and MobileNet_v2 later. I'd like to use the MobileNet_v2 as a direct link ot the "SneakerFinder" tool which motivated this experiment. [see SneakerFinder]</p>
<p>A variational "module" will sit between the encoder and decoder as the "Bottleneck". The Bottleneck will map the resnet features into a latent space (e.g. ~100 dimensions) represented of standard normal variables.  The "reparameterization trick" will sample from this space and the "decoder" will generate images.</p>
<p>Finally a simple "decoder" will sample from the variational latents space and be trained to reconstruct the images.</p>
<p>The intention is the latent space can be used to generate novel sneaker images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="AE:--deterministic-AutoEncoder-(-non--variational)">AE:  deterministic AutoEncoder ( <em>non- variational</em>)<a class="anchor-link" href="#AE:--deterministic-AutoEncoder-(-non--variational)"> </a></h3><p>Although we give up the original utility we are going for --  creating new sneakers via the latent space -- having otherwise equivalent non-variational autoencoders for reference will be great. Furthermore, this latent space representation will be amenable to a MMD regularization later on.  This will be useful to avoid some of the limitiations of the KLD as a regularizer (overestimation of variance, and some degenerate convergences).
Its sort of <em>hack</em>-ey but keeping the tooling equivalent to the betaVAE will ultimatel give some advantages.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UpsampleBlock" class="doc_header"><code>class</code> <code>UpsampleBlock</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L204" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UpsampleBlock</code>(<strong><code>up_in_c</code></strong>:<code>int</code>, <strong><code>final_div</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>blur</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LatentLayer" class="doc_header"><code>class</code> <code>LatentLayer</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L225" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LatentLayer</code>(<strong><code>in_features</code></strong>, <strong><code>latent_features</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>This layer encodes the latent "bottleneck" and is constructed to work with the specified VAE DataBlock be a replacement for
the variational (reparameter trick) layer for otherwise identical architecture</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AEEncoder" class="doc_header"><code>class</code> <code>AEEncoder</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L252" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AEEncoder</code>(<strong><code>arch_body</code></strong>, <strong><code>enc_dim</code></strong>, <strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AEDecoder" class="doc_header"><code>class</code> <code>AEDecoder</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L275" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AEDecoder</code>(<strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is convenient to avoid the class wrappers to simplify the param splitting for freezing the pre-trained arcitecture.<br>
We could enumerate the class layers and return sequential, but simply making some functions to put the layers togeter is better.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="build_AE_encoder" class="doc_header"><code>build_AE_encoder</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L316" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>build_AE_encoder</code>(<strong><code>arch_body</code></strong>, <strong><code>enc_dim</code></strong>, <strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>)</p>
</blockquote>
<p>wrapper to sequential-ize AEEncoder class</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="build_AE_decoder" class="doc_header"><code>build_AE_decoder</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L323" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>build_AE_decoder</code>(<strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>)</p>
</blockquote>
<p>wrapper to sequential-ize AEDecoder class</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AE" class="doc_header"><code>class</code> <code>AE</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L333" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AE</code>(<strong><code>enc_parts</code></strong>, <strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Loss">Loss<a class="anchor-link" href="#Loss"> </a></h4><p>These inherit from <code>Module</code>. (fastai's wrapper on <code>nn.Module</code>).  The base class <a href="/snkrfinder/model.cvae#AELoss"><code>AELoss</code></a> initializes wiht a <code>batchmean</code>, <code>alpha</code>, and <code>useL1</code> parameters to set how the loss will be aggregated and regularized.  For the basice AutoEncoder we'll regularize the latent with a L1 to keep the magnitudes from exploding.<br>
{% include note.html content='Here <code>batchmean</code> means we will divide the loss (either L1 or L2 depending on <code>useL1</code> flag) by which uses <code>reduction=&amp;#8217;sum&amp;#8217;</code> by the batch size.   This technically makes it a <em>cost</em> computed for each batch.   This same convention will be used later for KL-Divergence and MMD latent regularizers.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AELoss" class="doc_header"><code>class</code> <code>AELoss</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L410" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AELoss</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>, <strong><code>useL1</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>wrapper for loss_func which deals with potential annealed kl_weight
does MSE with 'mean' reduction
'batchmean'  averages as 'sum' MSE over batches
simple L1 regularizer on latent dimension</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Metrics">Metrics<a class="anchor-link" href="#Metrics"> </a></h4><p>These are called by the recorder callback and collect quantities to track training.  I made a simple meta class so I don't have to repreat the reset and mean value property for all the metrics.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MyMetric" class="doc_header"><code>class</code> <code>MyMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L458" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MyMetric</code>() :: <code>Metric</code></p>
</blockquote>
<p>meta-class for simple average over epoch metric quantities</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L1LatentReg" class="doc_header"><code>class</code> <code>L1LatentReg</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L467" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L1LatentReg</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>) :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Latent Regularizer with sum reduction and optinal batchmean scaling</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These are some helpers for computing the KL Divergence as a function and a <code>Module</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="KLD" class="doc_header"><code>KLD</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L489" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>KLD</code>(<strong><code>mu</code></strong>, <strong><code>logvar</code></strong>)</p>
</blockquote>
<p>KLD helper which sum across latents, but not batches</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="KLDiv" class="doc_header"><code>class</code> <code>KLDiv</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L494" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>KLDiv</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Module for computing the KL Divergence from a unit normal distribution.
'batchmean' option sums first and averages over batches</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L2MeanMetric" class="doc_header"><code>class</code> <code>L2MeanMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L526" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L2MeanMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Mean square error</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L1MeanMetric" class="doc_header"><code>class</code> <code>L1MeanMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L536" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L1MeanMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Mean absolute error</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L2Metric" class="doc_header"><code>class</code> <code>L2Metric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L546" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L2Metric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Sum square error</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L1Metric" class="doc_header"><code>class</code> <code>L1Metric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L556" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L1Metric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Sum absolute error</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L2BMeanMetric" class="doc_header"><code>class</code> <code>L2BMeanMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L567" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L2BMeanMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Summed square error average across batch</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="L1BMeanMetric" class="doc_header"><code>class</code> <code>L1BMeanMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L577" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>L1BMeanMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Summed abs error average across batch</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="KLWeightMetric" class="doc_header"><code>class</code> <code>KLWeightMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L588" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>KLWeightMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>Injected KLD weighting</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="RawKLDMetric" class="doc_header"><code>class</code> <code>RawKLDMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L597" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>RawKLDMetric</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>) :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>KLD Metric, <code>batchmean</code> averages across batches</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="WeightedKLDMetric" class="doc_header"><code>class</code> <code>WeightedKLDMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L610" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>WeightedKLDMetric</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>) :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>weighted KLD Metric, <code>batchmean</code> averages across batches
the "effective" KLD regularization in e.g. a ùú∑-BAE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MuMetric" class="doc_header"><code>class</code> <code>MuMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L630" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MuMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>average latent value (e.g. avg(<code>mu</code>)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MuSDMetric" class="doc_header"><code>class</code> <code>MuSDMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L639" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MuSDMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>standard deviation of latent ùùÅ value (e.g. std(<code>mu</code>) )</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="StdMetric" class="doc_header"><code>class</code> <code>StdMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L648" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>StdMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>average of latent ùùà value (e.g. std(exp(.5*<code>logvar</code>) )</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="StdSDMetric" class="doc_header"><code>class</code> <code>StdSDMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L657" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>StdSDMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>standard deviation of latent ùùà value (e.g. std(exp(.5*<code>logvar</code>) )</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LogvarMetric" class="doc_header"><code>class</code> <code>LogvarMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L666" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LogvarMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>average of latent log(ùùà*ùùà) value (e.g. mean(<code>logvar</code>))</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LogvarSDMetric" class="doc_header"><code>class</code> <code>LogvarSDMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L674" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LogvarSDMetric</code>() :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>standard deviation of latent log(ùùà*ùùà)  value (e.g. std(<code>logvar</code>)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="metrics-helpers">metrics helpers<a class="anchor-link" href="#metrics-helpers"> </a></h4>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="default_AE_metrics" class="doc_header"><code>default_AE_metrics</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L688" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>default_AE_metrics</code>(<strong><code>alpha</code></strong>, <strong><code>batchmean</code></strong>, <strong><code>useL1</code></strong>)</p>
</blockquote>
<p>long-ish default list of metrics for the AE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="short_AE_metrics" class="doc_header"><code>short_AE_metrics</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L708" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>short_AE_metrics</code>(<strong><code>alpha</code></strong>, <strong><code>batchmean</code></strong>, <strong><code>useL1</code></strong>)</p>
</blockquote>
<p>short default list of metrics for the AE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Callback---AnnealedLoss">Callback - AnnealedLoss<a class="anchor-link" href="#Callback---AnnealedLoss"> </a></h3><p>The AnnealedLoss Callback basically injects a kl_weight parameter into the loss so we can start training without the full KLD regularization for the beta-VAE version.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The fastai <code>Learner</code> class does the training loop.  It took me a little digging into the code to figure out how Metrics are called since its not really stated anywhere in the documentation (<em>Note: create PR for fastai for extra documentation on <code>Metrics</code> logic</em>).  By default one of the key <code>Callbacks</code> is the <code>Recorder</code>.  It prints out the training summary at each epoch (via <code>ProgressCallBack</code>) and collects all the <code>Metrics</code>. Which by default only loss is a <code>train_met</code> and others are <code>valid_met</code>.
The <code>Recorder</code> resets (maps <code>reset()</code> to all mets) the metrics <code>before_train</code> and <code>before_valid</code>. The <code>Recorder</code> maps <code>accumulate()</code> to the metrics on <code>after_batch</code>.  Finally</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>AnnealedLossCallback will inject the latent mu and logvar and a kl_weight variable into our loss.  The <code>mu</code> and <code>logvar</code> will be used to compute the KLD. The kl_weight is a scheduled weighting for the KLD. You can see the schedule graph of the parameter. At the beginning it will be 0, thus the KLD part of the loss will get ignored. So during 10% of training, we will fit a normal auto-encoder. Then gradually for 30% of trainning, increase kl_weight to 1 and then remain there for the remaining training time so that the auto encoder now becomes full variational. The way this callback is done, the loss will receive this parameter, but not the model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AnnealedLossCallback" class="doc_header"><code>class</code> <code>AnnealedLossCallback</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L725" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AnnealedLossCallback</code>(<strong><code>after_create</code></strong>=<em><code>None</code></em>, <strong><code>before_fit</code></strong>=<em><code>None</code></em>, <strong><code>before_epoch</code></strong>=<em><code>None</code></em>, <strong><code>before_train</code></strong>=<em><code>None</code></em>, <strong><code>before_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_pred</code></strong>=<em><code>None</code></em>, <strong><code>after_loss</code></strong>=<em><code>None</code></em>, <strong><code>before_backward</code></strong>=<em><code>None</code></em>, <strong><code>before_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_step</code></strong>=<em><code>None</code></em>, <strong><code>after_step</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_batch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_train</code></strong>=<em><code>None</code></em>, <strong><code>after_train</code></strong>=<em><code>None</code></em>, <strong><code>before_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_validate</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_epoch</code></strong>=<em><code>None</code></em>, <strong><code>after_cancel_fit</code></strong>=<em><code>None</code></em>, <strong><code>after_fit</code></strong>=<em><code>None</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>injects <code>kl_weight</code> for access during loss function calculation</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="default_KL_anneal_in" class="doc_header"><code>default_KL_anneal_in</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L736" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>default_KL_anneal_in</code>()</p>
</blockquote>
<p>reasonable default for 'warming up' the KL Div</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">f_init</span> <span class="o">=</span> <span class="n">combine_scheds</span><span class="p">([</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">SchedNo</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">SchedCos</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)])</span>
<span class="c1"># f = combine_scheds([.8, .2], [SchedCos(0,0), SchedCos(0,.5)])</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="o">*</span><span class="n">n_epochs</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pp</span><span class="p">,[</span><span class="n">f_init</span><span class="p">(</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">p</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include warning.html content='Avoid using early stopping because the AnnealedLossCallback will make the loss grow once the KL divergence weight kicks in. ' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I want to note something here that was a little confusing to me: <code>params(model)</code> is a builtin fastai <code>PyTorch.core</code> function which returns all of the parameters of the modules.    i.e.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">params</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="s2">&quot;Return all parameters of `m`&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
</pre></div>
<p>The toplevel <code>fastai core</code> functions with simple names that <em>almost</em> match class attributes was one of my biggest stumbling blocks in getting acquainted with the fastai v2 API.  (The other is the documentation which is <em>autogenerated</em> by the fastdev frameworks from their development noteboooks.  More on that struggle and my tips if that is troblesome for you later (here).
{% include note.html content='that it is crucial that you don&#8217;t freeze the batch norm layers.   The <a href="/snkrfinder/model.cvae#bn_splitter"><code>bn_splitter</code></a> collects out all the batchnorm layers.  The simple splitting we do only freezes the <code>encoder</code> and leaves the latent layers (i.e. VAE or linear encoding bottlenedck) and the <code>decoder</code> in a parameter group with the batchnorm layers.' %}</p>
<h4 id="parameter-Splitters">parameter <code>Splitters</code><a class="anchor-link" href="#parameter-Splitters"> </a></h4><p>{% include warning.html content='there are two completely different <code>splitter</code>s in the FastAI API.  This <code>splitter</code> groups the model parameters into groups for <code>freezing</code> and for progressive learning rates. (The other one is splits data into train and validate.  I got imminiently confused when I first started with the API by this.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>TODO:more sophisticated parameter splitting to enable progressive learning rates</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bn_splitter" class="doc_header"><code>bn_splitter</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L742" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bn_splitter</code>(<strong><code>m</code></strong>)</p>
</blockquote>
<p>splits all the batchnorm layers out</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="resnetVAE_split" class="doc_header"><code>resnetVAE_split</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L755" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>resnetVAE_split</code>(<strong><code>m</code></strong>)</p>
</blockquote>
<p>simple splitter to freeze the non batch norm pre-trained encoder</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AE_split" class="doc_header"><code>AE_split</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L764" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AE_split</code>(<strong><code>m</code></strong>)</p>
</blockquote>
<p>generic splitter for my AE classes- BVAE &amp; AE &amp; MMDVAE.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="other-encoder-and-decoder-types">other encoder and decoder types<a class="anchor-link" href="#other-encoder-and-decoder-types"> </a></h3><blockquote><ol>
<li><p>MobileNet_v2 as the encoder, as a continuation of the original Sneaker Finder</p>
</li>
<li><p>simple bowtie convolutional encoder / decoder (Mimics the GOAT medium blog)</p>
<ul>
<li>Architecture Hyperparameters:- Latent Size (research default 256, production default 32)        - Filter Factor Size (research default 16, production default 32)<ul>
<li>Latent Linear Hidden Layer Size (research default 2048, production default 1024)</li>
<li>The encoder architecture is as follows with research defaults from above:<ul>
<li>Input 3x128x128 (conv2d block [conv2d, batchnorm2d, relu])</li>
<li>16x64x64 (conv2d block [conv2d, batchnorm2d, relu])</li>
<li>32x32x32 (conv2d block [conv2d, batchnorm2d, relu])</li>
<li>64x16x16 (conv2d block [conv2d, batchnorm2d, relu])</li>
<li>128x8x8 (conv2d block [conv2d, batchnorm2d, relu])</li>
<li>Flatten to 8192</li>
<li>2048 (linear block [linear, batchnorm1d, relu])</li>
<li>Split the 2048 dimension into mu and log variance for the parameters of the latent distribution </li>
<li>Latent mu size 256 (linear layer only with bias)</li>
<li>Latent logvar size 256 (linear layer only with bias)</li>
</ul>
</li>
<li>In the middle here you can break out the BCE and KLD loss for the final loss term and use the standard reparam trick to sample from the latent distribution.</li>
<li>Decoder architecture an exact mirror <ul>
<li>Input 256</li>
<li>2048 (linear block [linear, relu])</li>
<li>8192 (linear block [linear, batchnorm1d, relu])</li>
<li>reshape (128x8x8)</li>
<li>64x16x16 (conv2d transpose block [convtranspose2d, batchnorm2d, relu])</li>
<li>32x32x32 (conv2d transpose block [convtranspose2d, batchnorm2d, relu])</li>
<li>16x64x64 (conv2d transpose block [convtranspose2d, batchnorm2d, relu])</li>
<li>3x128x128 (conv2d transpose [convtranspose2d, sigmoid]</li>
</ul>
</li>
<li>For weight initialization I used a normal distribution centered at zero with 0.02 set for the stddev. Optimizer: Adam with default parameters, if I were to do it over again I'd spend more time here understanding the learning dynamics. The dataset was about ~10,000 with a 70/20/10 split, batch size 64, over 120 epochs, with a learning schedule to reduce when the loss started to plateau. No crazy image augmentation just resizing and standards flips. I used the ANN package Annoy to do the NN search for prod, normalizing the embeddings and using the cosine similarity, ANN factor was 128 for num_trees. </li>
</ul>
</li>
</ul>
</li>
</ol>
<ol>
<li>MMD regularized VAE where the latents are drawn from a </li>
</ol>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>TODO:Ranger optimizer might really help .. test</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also use the transfer learning VAE tooling we previously built.  We just need to create the convolutional encoder and pass it in... Note that we don't have a pre-trained option, so DON'T FREEZE!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now just wrap that simple conv block architecture into a <em>builder</em>.   And a meta-wrapper to let us call the conv_encoder and pre-trained options with the same function.   (I'll also put the <a href="/snkrfinder/model.cvae#get_pretrained_parts"><code>get_pretrained_parts</code></a> function here now even though we won't use it till the next section, so that we can make the <a href="/snkrfinder/model.cvae#get_encoder_parts"><code>get_encoder_parts</code></a> generic wrapper handle both properly.)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_conv_parts" class="doc_header"><code>get_conv_parts</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L776" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_conv_parts</code>(<strong><code>im_size</code></strong>=<em><code>160</code></em>)</p>
</blockquote>
<p>make a simple convolutional ladder encoder</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_pretrained_parts" class="doc_header"><code>get_pretrained_parts</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L792" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_pretrained_parts</code>(<strong><code>arch</code></strong>=<em><code>'resnet18'</code></em>)</p>
</blockquote>
<p>this works for mobilnet_v2, resnet, and xresnet</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_encoder_parts" class="doc_header"><code>get_encoder_parts</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L803" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_encoder_parts</code>(<strong><code>enc_type</code></strong>=<em><code>'vanilla'</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">##   </span>


<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># equalize KLDiv wrt errors per pixel</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">IMG_SIZE</span><span class="o">*</span><span class="n">IMG_SIZE</span><span class="o">/</span><span class="n">latent_dim</span>
<span class="n">alpha</span> <span class="o">/=</span> <span class="mi">20</span>  <span class="c1"># 5% retularizer</span>

<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span> 
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>  <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_AE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;vanilla&#39;</span>

<span class="n">vae</span> <span class="o">=</span> <span class="n">AE</span><span class="p">(</span><span class="n">get_encoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>

<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">AELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span> <span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='The <code>to_fp16()</code> callbacks work but increasing the batch size doesn&#8217;t really speed things up.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># equalize KLDiv wrt errors per pixel</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">IMG_SIZE</span><span class="o">*</span><span class="n">IMG_SIZE</span><span class="o">/</span><span class="n">latent_dim</span>
<span class="n">alpha</span> <span class="o">/=</span> <span class="mi">20</span>  <span class="c1"># 5% retularizer</span>

<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span> 
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>  <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_AE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;vanilla&#39;</span>

<span class="n">vae</span> <span class="o">=</span> <span class="n">AE</span><span class="p">(</span><span class="n">get_encoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>

<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">AELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span> <span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="constructing-VAE-with-Module-Class-Layers">constructing VAE with Module Class Layers<a class="anchor-link" href="#constructing-VAE-with-Module-Class-Layers"> </a></h3><p>For several of the decoder and "sampler" layers I might want to turn off the nonlinearity to give us more reasonable "gaussian" outputs to the Variational layer and the generated image which will is compared with the ImageNetStats batch-normalized image.</p>
<blockquote><p>IMPORTANT VAE TIP!!!   Make sure NOT to use batch normalization and non-linearity in the linear layers of the VAE.  The normalization will affect the representation and the KLD constraints.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VAELinear" class="doc_header"><code>class</code> <code>VAELinear</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L811" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VAELinear</code>(<strong><code>in_features</code></strong>, <strong><code>latent_features</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>maps hidden (input) features to two latents (mu and logvar)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VAELayer" class="doc_header"><code>class</code> <code>VAELayer</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L823" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VAELayer</code>(<strong><code>in_features</code></strong>, <strong><code>latent_features</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>The VAE : in_features to latent_features through
    the "Variational" magic: "reparamaterization trick"</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="simple-BVAE-class-from-VAE-layer-class-components">simple BVAE class from VAE layer class components<a class="anchor-link" href="#simple-BVAE-class-from-VAE-layer-class-components"> </a></h3><p>This creates a pair of latents from which we can perform the "resample" trick. 
{% include note.html content='this is a $\beta$-VAE (hence <a href="/snkrfinder/model.cvae#BVAE"><code>BVAE</code></a> because we have a weighting factor for the KL Divergence regularazation factor which acts as a Legrangian).' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Putting it all together gives us our VAE!   Note that we'll pass in the "parts" of the encoder for ease of using pretrained (or not) architectures.   The model name will correspond to the architecture of the encoder via <code>name</code>.</p>
<p>Note that the <a href="/snkrfinder/model.cvae#BVAE"><code>BVAE</code></a> can simply inherit from the <a href="/snkrfinder/model.cvae#AE"><code>AE</code></a> class we defined above.  Really the only difference in the <code>__init__</code> function is that a <a href="/snkrfinder/model.cvae#VAELayer"><code>VAELayer</code></a> which performs the reparameterization trick replaces the <code>AElayer</code> as <code>self.bn</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BVAE" class="doc_header"><code>class</code> <code>BVAE</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L854" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BVAE</code>(<strong><code>enc_parts</code></strong>, <strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>) :: <a href="/snkrfinder/model.cvae#AE"><code>AE</code></a></p>
</blockquote>
<p>simple VAE made with an encoder passed in, and some builder function for the Latent (VAE reparam trick) and decoder</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We defined a nice wrapper for building the encoder parts above.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_pretrained_parts</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="n">resnet18</span><span class="p">):</span>
    <span class="s2">&quot;this works for mobilnet_v2, resnet, and xresnet&quot;</span>
    <span class="n">cut</span> <span class="o">=</span> <span class="n">model_meta</span><span class="p">[</span><span class="n">arch</span><span class="p">][</span><span class="s1">&#39;cut&#39;</span><span class="p">]</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">arch</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">arch</span> <span class="o">=</span> <span class="n">arch</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">enc_arch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">arch</span><span class="o">.</span><span class="n">children</span><span class="p">())[:</span><span class="n">cut</span><span class="p">]</span>
    <span class="n">enc_feats</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="k">return</span> <span class="n">enc_arch</span><span class="p">,</span> <span class="n">enc_feats</span><span class="p">,</span> <span class="n">name</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sweet, we've verified the arcitecture works, but we need to train it with a loss that constrains the variational layers with the KL Divergence.  Otherwise the simple MSE will diverge.</p>
<h3 id="VAE-Loss-functions-classes">VAE Loss functions classes<a class="anchor-link" href="#VAE-Loss-functions-classes"> </a></h3><p>This simply adds a KLD regularizer to the latent space defined by two rank-1 tensors defining gaussian-prior latents.  i.e. a mean ($\mu$) and standard deviation ($\sigma$).<br>
{% include note.html content='for convenience and numeric stability the $\sigma$ is representated as a $\log(\sigma^{s})$ so the tensors are called <code>mu</code> and <code>logvar</code>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BVAELoss" class="doc_header"><code>class</code> <code>BVAELoss</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L936" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BVAELoss</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>, <strong><code>useL1</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Measures how well we have created the original image,
plus the KL Divergence with the unit normal distribution
batchmean option sums first and averages over batches (for smaller total error magnitudes.. cosmentic)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="default_VAE_metrics" class="doc_header"><code>default_VAE_metrics</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L981" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>default_VAE_metrics</code>(<strong><code>alpha</code></strong>, <strong><code>batchmean</code></strong>, <strong><code>useL1</code></strong>)</p>
</blockquote>
<p>long default list of metrics for the VAE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="short_VAE_metrics" class="doc_header"><code>short_VAE_metrics</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1004" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>short_VAE_metrics</code>(<strong><code>alpha</code></strong>, <strong><code>batchmean</code></strong>, <strong><code>useL1</code></strong>)</p>
</blockquote>
<p>short default list of metrics for the AE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's how we put everything together.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>


<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use this callback if we want to save the model at every epoch.  Which could be super useful if we were able to actually overfit our model.</p>
<blockquote><p>'SaveModelCallback(fname=datetime.now().strftime('%Y-%m-%d %Hh%M.%S'), every_epoch=True)'</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># NOTE: lf_finder does NOT work correctly with our annealed kl_weight... </span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='The CallBacks need to be updated for the KL loss annealing schedule as we tune.  We want to turn the <code>kl_weight</code> to 1.0 for instance when using the learning rate finder <code>learn.lr_find()</code>, and after an initial <em>burn in</em> where the KL_loss term gradually ramps in, setting the <code>kl_weight</code> to stay at unity will be useful as we separately turn the learning rate (e.g. <code>fit_one_cycle</code> or <code>fit_flat_cosine</code>.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#put in the annealied KL_weight...</span>
<span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>

<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">default_KL_anneal_in</span><span class="p">()}</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1">#learn.fit_one_cycle(n_epochs,lr_max= lr1)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The vae with pretrained resnet encoder seems to train to a much better end-point if we keep the resnet frozen.  Hence the commented out <code>learn.unfreeze()</code> below.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})</span> <span class="p">)</span>

<span class="c1">#learn.unfreeze()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1">#learn.fit_one_cycle(epochs, lr_max= 1e-3)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">pct_start</span><span class="o">=.</span><span class="mi">05</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&quot;Vanilla&quot;-convolutional-beta-VAE">"<em>Vanilla</em>" convolutional beta-VAE<a class="anchor-link" href="#&quot;Vanilla&quot;-convolutional-beta-VAE"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># equalize KLDiv wrt errors per pixel</span>
<span class="c1">#  alpha = 3*IMG_SIZE*IMG_SIZE/latent_dim</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">default_KL_anneal_in</span><span class="p">()</span> <span class="p">})]</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;vanilla&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">BVAE</span><span class="p">(</span><span class="n">get_encoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
                   
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">BVAELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MMD-VAE">MMD-VAE<a class="anchor-link" href="#MMD-VAE"> </a></h2><p>The MMD replace latent regularization term in loss_fn (KLD) with Maximal Meanm Discrepancy.</p>
<p>We'll make an MMDVAE class to keep things declarative, but its really just an AE. i.e. a linear latent layer.</p>
<p>Additional background on MME from [<a href="https://github.com/Saswatm123/MMD-VAE">https://github.com/Saswatm123/MMD-VAE</a>]:</p>
<blockquote><p>Maximum Mean Discrepancy Variational Autoencoder, a member of the InfoVAE family that maximizes Mutual Information between the Isotropic Gaussian Prior (as the latent space) and the Data Distribution.\
Short explanation:The traditional VAE is known as the ELBO-VAE, named after the Evidence Lower Bound used in its objective. The ELBO suffers from two problems: overestimation of latent variance, and uninformative latent information.\The latter is because one of the objective's terms is the KL-Divergence between the Gaussian parameterized by the encoder and the Standard Isotropic Gaussian. This dissuades usage of the latent code, so that the KL-Divergence term is allowed to fall even further. It is important to note that the KL-Divergence should never truly reach zero, as that means the encoder is not learning useful features and cannot find feature locality, and the decoder is just randomly sampling from Standard Gaussian noise.\
The overestimation of variance results from the KL-Divergence term not being strong enough to balance against the Reconstruction Error, and thus the Encoder prefers to learn a multimodal latent distribution with spread apart means, leading to low training error as it overfits, but low quality samples as well, as the sampling distribution is assumed to be a Standard Isotropic Gaussian. One effort to mitigate this effect is the Disentangled Variational Autoencoder, which simply raises the weight on the KL-Divergence term. However, this increases the problem stated in the paragraph above since it further penalizes using the latent code.\
For more detailed explanations, I used these resources to learn, in order of usefulness to me:\</p>

<pre><code>- https://arxiv.org/pdf/1706.02262.pdf \
- http://ruishu.io/2018/03/14/vae/ \
- http://approximateinference.org/accepted/HoffmanJohnson2016.pdf \
- https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/ \
- http://bjlkeng.github.io/posts/variational-bayes-and-the-mean-field-approximation/ \
- https://ermongroup.github.io/cs228-notes/inference/variational/ \</code></pre>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gaussian_kernel" class="doc_header"><code>gaussian_kernel</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1025" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gaussian_kernel</code>(<strong><code>a</code></strong>, <strong><code>b</code></strong>)</p>
</blockquote>
<p>helper for computing MMD</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="MMD" class="doc_header"><code>MMD</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1036" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>MMD</code>(<strong><code>a</code></strong>, <strong><code>b</code></strong>)</p>
</blockquote>
<p>Max Mean Discrepancy</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="rawMMD" class="doc_header"><code>rawMMD</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1040" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>rawMMD</code>(<strong><code>a</code></strong>, <strong><code>b</code></strong>)</p>
</blockquote>
<p><em>raw</em> values from gauss kernals, assuming that and b have the same shape</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MMDVAE" class="doc_header"><code>class</code> <code>MMDVAE</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1047" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MMDVAE</code>(<strong><code>enc_parts</code></strong>, <strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>) :: <a href="/snkrfinder/model.cvae#AE"><code>AE</code></a></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MaxMeanDiscrepancy" class="doc_header"><code>class</code> <code>MaxMeanDiscrepancy</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1050" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MaxMeanDiscrepancy</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>MMD
add alpha?</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MMDLoss" class="doc_header"><code>class</code> <code>MMDLoss</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1095" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MMDLoss</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>, <strong><code>useL1</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Measures mean square error of prediction and original image,
regularized by MMD.</p>
<p>Note: using reuction = 'mean' because it keeps the regularization relatively potent (i.e. pixels&gt;&gt;latents)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MMDMetric" class="doc_header"><code>class</code> <code>MMDMetric</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1151" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MMDMetric</code>(<strong><code>batchmean</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>) :: <a href="/snkrfinder/model.cvae#MyMetric"><code>MyMetric</code></a></p>
</blockquote>
<p>meta-class for simple average over epoch metric quantities</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="short_MMEVAE_metrics" class="doc_header"><code>short_MMEVAE_metrics</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1173" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>short_MMEVAE_metrics</code>(<strong><code>alpha</code></strong>, <strong><code>batchmean</code></strong>, <strong><code>useL1</code></strong>)</p>
</blockquote>
<p>short list of metrics for the VAE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="default_MMEVAE_metrics" class="doc_header"><code>default_MMEVAE_metrics</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1188" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>default_MMEVAE_metrics</code>(<strong><code>alpha</code></strong>, <strong><code>batchmean</code></strong>, <strong><code>useL1</code></strong>)</p>
</blockquote>
<p>long default list of metrics for the VAE</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Vanilla-MMD-VAE">Vanilla MMD VAE<a class="anchor-link" href="#Vanilla-MMD-VAE"> </a></h4><p>Simply call our <a href="/snkrfinder/model.cvae#get_encoder_parts"><code>get_encoder_parts</code></a> with <code>arch='vanilla'</code> in the <a href="/snkrfinder/model.cvae#MMDVAE"><code>MMDVAE</code></a> builder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;vanilla&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">MMDVAE</span><span class="p">(</span><span class="n">get_encoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span> <span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ResNet-Encoder-MMDVAE">ResNet Encoder MMDVAE<a class="anchor-link" href="#ResNet-Encoder-MMDVAE"> </a></h3><p>We build these by passing <code>resnet18</code> (<em>not</em> <code>'resnet18'</code>) to <a href="/snkrfinder/model.cvae#get_encoder_parts"><code>get_encoder_parts</code></a> helper for the parts to init the <a href="/snkrfinder/model.cvae#MMDVAE"><code>MMDVAE</code></a>.</p>
<p>First a traditional "fine_tune" type of training:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>


<span class="n">arch</span><span class="o">=</span><span class="n">resnet18</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">MMDVAE</span><span class="p">(</span><span class="n">get_encoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span> <span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
    
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1">#learn.fit_flat_cos(n_epoch) #, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span><span class="c1">#, lr=lr1, div_final=1e5, pct_start=0.5)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span><span class="c1">#,lr_max=gmlr) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="c1">#learn.fit_flat_cos(n_epoch, lr=lr1, div_final=1e6, pct_start=0.7)</span>
<span class="c1">#learn.fit_flat_cos(n_epoch, lr=1e-3, div_final=1e5, pct_start=0.5)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span> <span class="c1">#, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="vanilla-resnet-MMD-VAE">vanilla-resnet MMD VAE<a class="anchor-link" href="#vanilla-resnet-MMD-VAE"> </a></h4><h5 id="no-freeze">no freeze<a class="anchor-link" href="#no-freeze"> </a></h5><p>We build these by passing <code>resnet18</code> (<em>not</em> <code>'resnet18'</code>) to <a href="/snkrfinder/model.cvae#get_encoder_parts"><code>get_encoder_parts</code></a> helper for the parts to init the <a href="/snkrfinder/model.cvae#MMDVAE"><code>MMDVAE</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='our architecture trains best when simply starting with the pretrained weights.  Trying to "fine_tune" by training the backend on a <em>frozen</em> resnet and then unfreezing doesn&#8217;t work with the parameter groupings from the <a href="/snkrfinder/model.cvae#AE_split"><code>AE_split</code></a>.  The <code>learn.unfreeze()</code> doesn&#8217;t actually do anythign (<em>unfrozen</em> is default) but makes is clear we are <em>un</em> -frozen' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>


<span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>


<span class="n">arch</span><span class="o">=</span><span class="n">resnet18</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">MMDVAE</span><span class="p">(</span><span class="n">get_encoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span> <span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
    
    
    
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="vanilla-resnet-MMD-VAE">vanilla-resnet MMD-VAE<a class="anchor-link" href="#vanilla-resnet-MMD-VAE"> </a></h2><h5 id="ResBlocks-replacing-Conv2d-in-encoder-AND-decoder.">ResBlocks replacing Conv2d in encoder AND decoder.<a class="anchor-link" href="#ResBlocks-replacing-Conv2d-in-encoder-AND-decoder."> </a></h5><p>'Vanilla' encoder architecture made with <code>ResBlock</code> layers instead of <code>ConvLayer</code> layers and <code>Mish</code> activation.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UpsampleResBlock" class="doc_header"><code>class</code> <code>UpsampleResBlock</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1212" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UpsampleResBlock</code>(<strong><code>up_in_c</code></strong>:<code>int</code>, <strong><code>final_div</code></strong>:<code>bool</code>=<em><code>True</code></em>, <strong><code>blur</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_resblockencoder_parts" class="doc_header"><code>get_resblockencoder_parts</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1230" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_resblockencoder_parts</code>(<strong><code>enc_type</code></strong>=<em><code>'vanilla'</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>)</p>
</blockquote>
<p>make a simple (hence 'vanilla') convolutional ladder encoder with ResBlock parts</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResBlockAEDecoder" class="doc_header"><code>class</code> <code>ResBlockAEDecoder</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1275" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResBlockAEDecoder</code>(<strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="build_ResBlockAE_decoder" class="doc_header"><code>build_ResBlockAE_decoder</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1312" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>build_ResBlockAE_decoder</code>(<strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>)</p>
</blockquote>
<p>wrapper to sequential-ize ResBlockAEDecoder class</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResBlockAE" class="doc_header"><code>class</code> <code>ResBlockAE</code><a href="https://github.com/ergonyc/snkrfinder/tree/master/snkrfinder/model/cvae.py#L1319" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResBlockAE</code>(<strong><code>enc_parts</code></strong>, <strong><code>hidden_dim</code></strong>=<em><code>None</code></em>, <strong><code>latent_dim</code></strong>=<em><code>128</code></em>, <strong><code>im_size</code></strong>=<em><code>160</code></em>, <strong><code>out_range</code></strong>=<em><code>[-1, 1]</code></em>, <strong><code>isVAE</code></strong>=<em><code>False</code></em>) :: <a href="/snkrfinder/model.cvae#AE"><code>AE</code></a></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we can use the <code>ResBlockBVAE</code> which instantiates a <code>ResBlock</code> <code>decoder</code> to optimize the architecture.  This is following the fastAI API lessong from the "bag of tricks" ResNet paper (CITATION), which is a general true-ism which could be glibly states as: "replacing a <code>Conv</code> with a <code>ResBlock</code> always gets you better results".  The Class constructor <a href="/snkrfinder/model.cvae#ResBlockAE"><code>ResBlockAE</code></a> takes <code>isVAE</code> to switch between <code>AELayer</code> and <a href="/snkrfinder/model.cvae#LatentLayer"><code>LatentLayer</code></a> latents.</p>
<blockquote><p>TODO:update AE class to make a VAE or AE based on the <code>isVAE</code> switch</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># doubled because latent is half?</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>


<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resnblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">,</span><span class="n">isVAE</span><span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
                   
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">BVAELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="next-steps.">next steps.<a class="anchor-link" href="#next-steps."> </a></h2><ul>
<li>visualize activations in encoder decoder</li>
<li>improve training with progressive learning rates</li>
<li>G</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="export-/-provenance">export / provenance<a class="anchor-link" href="#export-/-provenance"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="128-latents,-alpha=10">128 latents, alpha=10<a class="anchor-link" href="#128-latents,-alpha=10"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># cbs = [AnnealedLossCallback(),TerminateOnNaNCallback(),         </span>
<span class="c1">#                SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True),</span>
<span class="c1">#                ParamScheduler({&#39;kl_weight&#39;: SchedNo(1.,1.) })]</span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># note that alpha needs to be adjusted to scale MMD regularizer compared to error for batchmean=true</span>
<span class="c1">#.  e.g.  *= 3*IMG_SIZE**2/latent_dim</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>  <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
  
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
     
    
    
    

    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#learn.freeze()</span>
<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1">#learn.fit_flat_cos(n_epoch) #, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span><span class="c1">#, lr=lr1, div_final=1e5, pct_start=0.5)</span>
<span class="c1">#learn.fit_one_cycle(n_epoch,lr_max=gmlr) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MMDVae-</span><span class="si">{</span><span class="s1">&#39;TMP&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;frozen-</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="c1">#learn.export(f&#39;{filename}.pkl&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="128-latents,-alpha=20">128 latents, alpha=20<a class="anchor-link" href="#128-latents,-alpha=20"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># cbs = [AnnealedLossCallback(),TerminateOnNaNCallback(),         </span>
<span class="c1">#                SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True),</span>
<span class="c1">#                ParamScheduler({&#39;kl_weight&#39;: SchedNo(1.,1.) })]</span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># note that alpha needs to be adjusted to scale MMD regularizer compared to error for batchmean=true</span>
<span class="c1">#.  e.g.  *= 3*IMG_SIZE**2/latent_dim</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>  <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
  
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
     
    
    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#learn.freeze()</span>
<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1">#learn.fit_flat_cos(n_epoch) #, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span><span class="c1">#, lr=lr1, div_final=1e5, pct_start=0.5)</span>
<span class="c1">#learn.fit_one_cycle(n_epoch,lr_max=gmlr) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MMDVae-</span><span class="si">{</span><span class="s1">&#39;TMP&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;frozen-</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="c1">#learn.export(f&#39;{filename}.pkl&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="64-latents,-alpha=10">64 latents, alpha=10<a class="anchor-link" href="#64-latents,-alpha=10"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># cbs = [AnnealedLossCallback(),TerminateOnNaNCallback(),         </span>
<span class="c1">#                SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True),</span>
<span class="c1">#                ParamScheduler({&#39;kl_weight&#39;: SchedNo(1.,1.) })]</span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># note that alpha needs to be adjusted to scale MMD regularizer compared to error for batchmean=true</span>
<span class="c1">#.  e.g.  *= 3*IMG_SIZE**2/latent_dim</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>  <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
  
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
     
    
    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#learn.freeze()</span>
<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1">#learn.fit_flat_cos(n_epoch) #, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span><span class="c1">#, lr=lr1, div_final=1e5, pct_start=0.5)</span>
<span class="c1">#learn.fit_one_cycle(n_epoch,lr_max=gmlr) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MMDVae-</span><span class="si">{</span><span class="s1">&#39;TMP&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;frozen-</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="c1">#learn.export(f&#39;{filename}.pkl&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="64-latents,-alpha-=-20">64 latents, alpha = 20<a class="anchor-link" href="#64-latents,-alpha-=-20"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># cbs = [AnnealedLossCallback(),TerminateOnNaNCallback(),         </span>
<span class="c1">#                SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True),</span>
<span class="c1">#                ParamScheduler({&#39;kl_weight&#39;: SchedNo(1.,1.) })]</span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span>         
               <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># note that alpha needs to be adjusted to scale MMD regularizer compared to error for batchmean=true</span>
<span class="c1">#.  e.g.  *= 3*IMG_SIZE**2/latent_dim</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_MMEVAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>  <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
  
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">MMDLoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
     
    
    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#learn.freeze()</span>
<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1">#learn.fit_flat_cos(n_epoch) #, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">)</span><span class="c1">#, lr=lr1, div_final=1e5, pct_start=0.5)</span>
<span class="c1">#learn.fit_one_cycle(n_epoch,lr_max=gmlr) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MMDVae-</span><span class="si">{</span><span class="s1">&#39;TMP&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;frozen-</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="c1">#learn.export(f&#39;{filename}.pkl&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="vanilla-resnet-beta-VAE">vanilla-resnet beta-VAE<a class="anchor-link" href="#vanilla-resnet-beta-VAE"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ResBlockBVAE</span><span class="p">(</span><span class="n">BVAE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    simple VAE with a _probably_ pretrained encoder </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">enc_parts</span><span class="p">,</span><span class="n">hidden_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">):</span>
       
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        inputs:  </span>
<span class="sd">            enc_arch (pre-cut / pretrained)</span>
<span class="sd">            enc_dim</span>
<span class="sd">            latent_dim</span>
<span class="sd">            hidden_dim</span>
<span class="sd">            im_size,out_range</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">enc_arch</span><span class="p">,</span><span class="n">enc_feats</span><span class="p">,</span><span class="n">name</span> <span class="o">=</span> <span class="n">enc_parts</span>

        <span class="c1"># encoder</span>
        <span class="c1">#  arch,cut = xresnet18(pretrained=True),-4</span>
        <span class="c1">#  enc_arch = list(arch.children())[:cut]</span>
        
        <span class="n">BASE</span> <span class="o">=</span> <span class="n">im_size</span><span class="o">//</span><span class="mi">2</span><span class="o">**</span><span class="mi">5</span>
        <span class="n">enc_dim</span> <span class="o">=</span> <span class="n">enc_feats</span> <span class="o">*</span> <span class="n">BASE</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># 2**(3*3) * (im_size//32)**2 #(output of resneet) #12800</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">build_AE_encoder</span><span class="p">(</span><span class="n">enc_arch</span><span class="p">,</span><span class="n">enc_dim</span><span class="o">=</span><span class="n">enc_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">im_size</span><span class="p">)</span>

        <span class="n">in_dim</span> <span class="o">=</span> <span class="n">enc_dim</span> <span class="k">if</span> <span class="n">hidden_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">hidden_dim</span>

        <span class="c1"># VAE Bottleneck</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">VAELayer</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span><span class="n">latent_dim</span><span class="p">)</span>     

        <span class="c1">#decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">build_ResBlockAE_decoder</span><span class="p">(</span><span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">im_size</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">out_range</span><span class="p">)</span>

        <span class="n">store_attr</span><span class="p">(</span><span class="s1">&#39;name,enc_dim, in_dim,hidden_dim,latent_dim,im_size,out_range&#39;</span><span class="p">)</span> <span class="c1"># do i need all these?</span>




<span class="c1">#  THESE ARE INHERITED..</span>
<span class="c1">#     def decode(self, z):    </span>
<span class="c1">#         z = self.decoder(z)</span>
<span class="c1">#         return z</span>
    
<span class="c1">#     def reparam(self, h):</span>
<span class="c1">#         return self.bn(h)</span>

<span class="c1">#     def encode(self, x):</span>
<span class="c1">#         h = self.encoder(x)</span>
<span class="c1">#         z, mu, logvar = self.reparam(h)</span>
<span class="c1">#         return z, mu, logvar</span>

<span class="c1">#     def forward(self, x):</span>
<span class="c1">#         z, mu, logvar = self.encode(x)</span>
<span class="c1">#         x_hat = self.decode(z)</span>
<span class="c1">#         latents = torch.stack([mu,logvar],dim=-1)</span>
<span class="c1">#         return x_hat, latents # assume dims are [batch,latent_dim,concat_dim]</span>
        
        
        
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="128-latents,-alpha=5">128 latents, alpha=5<a class="anchor-link" href="#128-latents,-alpha=5"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># doubled because latent is half?</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>


<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resnblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockBVAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
                   
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">BVAELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">default_KL_anneal_in</span><span class="p">()}</span> <span class="p">)</span> <span class="p">)</span>

<span class="c1">#fit the backend of the VAE (n)</span>
<span class="c1"># the defaults are pretty good for now</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1">#learn.fit_one_cycle(freeze_epochs1,lr_max= lr1)#, lr_max= base_lr)</span>
<span class="c1">#learn.fit_flat_cos(n_epochs, lr=lr1, pct_start=0.5)</span>
<span class="c1">#learn.fit_flat_cos(n_epochs) #, lr=1e-4,pct_start=0.5)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span><span class="c1">#, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This initial "burning in" of the KLD regularization is very unstable...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})</span> <span class="p">)</span>

<span class="c1">#learn.unfreeze()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>

<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">base_lr</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="c1"># gmlr #/= 2</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1">#learn.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div)</span>
<span class="c1">#learn.fit_one_cycle(epochs, lr_max= 1e-3)</span>
<span class="c1">#learn.fit_flat_cos(epochs,lr=lr1,pct_start=.05)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">div_final</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span><span class="c1">#,lr=1e-4)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;BVae-</span><span class="si">{</span><span class="s1">&#39;2step10_100&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="128-latents,-alpha=10">128 latents, alpha=10<a class="anchor-link" href="#128-latents,-alpha=10"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># doubled because latent is half?</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>



<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>


<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resnblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockBVAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
                   
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">BVAELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">default_KL_anneal_in</span><span class="p">()}</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># # the defaults are pretty good for now</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span><span class="c1">#, lr_max= base_lr)</span>
<span class="c1"># #learn.fit_flat_cos(n_epochs, lr=lr1, pct_start=0.5)</span>
<span class="c1"># learn.fit_flat_cos(n_epochs, lr=1e-4,pct_start=0.5)</span>

<span class="c1"># learn.show_results()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># # the defaults are pretty good for now</span>
<span class="c1"># n_epochs = 10</span>

<span class="c1"># learn.fit_one_cycle(10)#, lr_max= base_lr)</span>
<span class="c1"># #learn.fit_flat_cos(n_epochs, lr=lr1, pct_start=0.5)</span>
<span class="c1"># #learn.fit_flat_cos(n_epochs, lr=1e-4,pct_start=0.5)</span>

<span class="c1"># learn.show_results()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This initial "burning in" of the KLD regularization is very unstable...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})</span> <span class="p">)</span>

<span class="c1">#learn.unfreeze()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>

<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1">#learn.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div)</span>
<span class="c1">#learn.fit_one_cycle(epochs, lr_max= 1e-3)</span>
<span class="c1">#learn.fit_flat_cos(epochs,lr=lr1,pct_start=.05)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">div_final</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span><span class="c1">#,lr=1e-4)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># filename = f&quot;{prefix}-{learn.model.name}-alpha{alpha:d}_{datetime.now().strftime(&#39;%Y-%m-%d_%H.%M.%S&#39;)}&quot;</span>

<span class="c1"># learn.save(filename)</span>
<span class="c1"># learn.export(f&#39;{filename}.pkl&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># base_lr = 1e-5# gmlr #/= 2</span>
<span class="c1"># epochs = 50</span>

<span class="c1"># #learn.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div)</span>
<span class="c1"># #learn.fit_one_cycle(epochs, lr_max= 1e-3)</span>
<span class="c1"># #learn.fit_flat_cos(epochs,lr=lr1,pct_start=.05)</span>
<span class="c1"># learn.fit_flat_cos(epochs)</span>
<span class="c1"># learn.show_results()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># filename = f&quot;{prefix}-{learn.model.name}-alpha{alpha:d}_{datetime.now().strftime(&#39;%Y-%m-%d_%H.%M.%S&#39;)}&quot;</span>

<span class="c1"># learn.save(filename)</span>
<span class="c1"># learn.export(f&#39;{filename}.pkl&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># filename = f&quot;{prefix}-{learn.model.name}-alpha{alpha:d}_{datetime.now().strftime(&#39;%Y-%m-%d_%H.%M.%S&#39;)}&quot;</span>
<span class="c1"># filename = &quot;BVae-POST-1CYCLE10-latent128-resblock-alpha10_2021-03-24_21.33.02&quot;</span>
<span class="c1"># learn.load(filename)</span>
<span class="c1"># #epochs = 5</span>
<span class="c1"># epochs = 10</span>
<span class="c1"># learn.fit_one_cycle(epochs, lr_max=.001)</span>
<span class="c1"># #learn.fit_flat_cos(epochs,lr=.0015,pct_start=.5,div_final=1000.0)</span>
<span class="c1"># #learn.fit_one_cycle(epochs,lr_max=5e-3,pct_start=0.5,div_final=100000) # gets down to ~4500 loss in 10</span>
<span class="c1"># learn.show_results()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;BVae-</span><span class="si">{</span><span class="s1">&#39;2step10_100&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="64-latents,-alpha=5">64 latents, alpha=5<a class="anchor-link" href="#64-latents,-alpha=5"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># doubled because latent is half?</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>


<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>


<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resnblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockBVAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
                   
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">BVAELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">default_KL_anneal_in</span><span class="p">()}</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span><span class="c1">#,lr_max= lr1)#, lr_max= base_lr)</span>
<span class="c1">#learn.fit_flat_cos(n_epochs, lr=lr1, pct_start=0.5)</span>
<span class="c1">#learn.fit_flat_cos(n_epochs, lr=1e-4,pct_start=0.5)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This initial "burning in" of the KLD regularization is very unstable...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})</span> <span class="p">)</span>

<span class="c1">#learn.unfreeze()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>

<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">base_lr</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="c1"># gmlr #/= 2</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1">#learn.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div)</span>
<span class="c1">#learn.fit_one_cycle(epochs, lr_max= 1e-3)</span>
<span class="c1">#learn.fit_flat_cos(epochs,lr=lr1,pct_start=.05)</span>
<span class="c1">#learn.fit_flat_cos(epochs,lr=1e-4)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">div_final</span><span class="o">=</span><span class="mf">1000.0</span><span class="p">)</span><span class="c1">#,lr=1e-3)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;BVae-</span><span class="si">{</span><span class="s1">&#39;2step10_100&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="64-latents,-alpha=10">64 latents, alpha=10<a class="anchor-link" href="#64-latents,-alpha=10"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># doubled because latent is half?</span>
<span class="n">batchmean</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">useL1</span> <span class="o">=</span> <span class="kc">False</span>


<span class="c1"># SaveModelCallback(fname=datetime.now().strftime(&#39;%Y-%m-%d %Hh%M.%S&#39;), every_epoch=True), </span>
<span class="n">cbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">AnnealedLossCallback</span><span class="p">(),</span><span class="n">TerminateOnNaNCallback</span><span class="p">(),</span> <span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})]</span>


<span class="n">metrics</span> <span class="o">=</span> <span class="n">default_VAE_metrics</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="n">batchmean</span><span class="p">,</span><span class="n">useL1</span><span class="p">)</span>


<span class="n">block</span> <span class="o">=</span> <span class="n">get_ae_DataBlock</span><span class="p">(</span><span class="n">aug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">block</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">arch</span><span class="o">=</span><span class="s1">&#39;resnblock&#39;</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">ResBlockBVAE</span><span class="p">(</span><span class="n">get_resblockencoder_parts</span><span class="p">(</span><span class="n">arch</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span><span class="n">latent_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">im_size</span><span class="o">=</span><span class="n">IMG_SIZE</span><span class="p">,</span><span class="n">out_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">)</span>
                   
<span class="c1"># let beta be calculated by : 3*im_size*im_size/latent_dim</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">BVAELoss</span><span class="p">(</span><span class="n">batchmean</span><span class="o">=</span><span class="n">batchmean</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span><span class="n">useL1</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">cbs</span><span class="p">,</span><span class="n">loss_func</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span><span class="n">splitter</span><span class="o">=</span><span class="n">AE_split</span><span class="p">)</span><span class="c1">#.to_fp16() #wd=config[&#39;wd&#39;],opt_func=ranger,</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span> <span class="n">default_KL_anneal_in</span><span class="p">()}</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the defaults are pretty good for now</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span><span class="c1">#,lr_max= lr1)#, lr_max= base_lr)</span>
<span class="c1">#learn.fit_flat_cos(n_epochs, lr=lr1, pct_start=0.5)</span>
<span class="c1">#learn.fit_flat_cos(n_epochs, lr=1e-4,pct_start=0.5)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This initial "burning in" of the KLD regularization is very unstable...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">remove_cb</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">cbs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># add new constant scheduler</span>
<span class="n">learn</span><span class="o">.</span><span class="n">add_cb</span><span class="p">(</span><span class="n">ParamScheduler</span><span class="p">({</span><span class="s1">&#39;kl_weight&#39;</span><span class="p">:</span>  <span class="n">SchedNo</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">)</span> <span class="p">})</span> <span class="p">)</span>

<span class="c1">#learn.unfreeze()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>

<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">base_lr</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="c1"># gmlr #/= 2</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1">#learn.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div)</span>
<span class="c1">#learn.fit_one_cycle(epochs, lr_max= 1e-3)</span>
<span class="c1">#learn.fit_flat_cos(epochs,lr=lr1,pct_start=.05)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span><span class="n">div_final</span><span class="o">=</span><span class="mf">1000.</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;BVae-</span><span class="si">{</span><span class="s1">&#39;2step10_100&#39;</span><span class="si">}</span><span class="s2">-latent</span><span class="si">{</span><span class="n">latent_dim</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CODE-graveyard">CODE graveyard<a class="anchor-link" href="#CODE-graveyard"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LatentTuple</span><span class="p">(</span><span class="n">fastuple</span><span class="p">):</span>
    <span class="s2">&quot;Basic type for tuple of tensor (vectors)&quot;</span>
    <span class="n">_show_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">ts</span><span class="p">):</span> 
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span><span class="nb">tuple</span><span class="p">):</span>
            <span class="n">mu</span><span class="p">,</span><span class="n">logvar</span> <span class="o">=</span> <span class="n">ts</span>
        <span class="k">elif</span> <span class="n">ts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span><span class="n">logvar</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">logvar</span> <span class="o">=</span> <span class="kc">None</span>
            
        <span class="k">if</span> <span class="n">mu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> 
        
        <span class="k">if</span> <span class="n">logvar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logvar</span><span class="p">,</span><span class="n">Tensor</span><span class="p">):</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">logvar</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span> <span class="p">(</span><span class="n">mu</span><span class="p">,</span><span class="n">logvar</span><span class="p">)</span> <span class="p">)</span> 
        
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> 
        <span class="n">mu</span><span class="p">,</span><span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">logvar</span><span class="p">,</span><span class="n">Tensor</span><span class="p">):</span> <span class="k">return</span> <span class="n">ctx</span>

        <span class="n">title_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;mu-&gt; </span><span class="si">{</span><span class="n">mu</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">e</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">mu</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">e</span><span class="si">}</span><span class="s2">  logvar-&gt;</span><span class="si">{</span><span class="n">logvar</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">e</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">logvar</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">e</span><span class="si">}</span><span class="s2">&quot;</span>
    
        <span class="k">if</span> <span class="s1">&#39;figsize&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span> <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;figsize&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;title&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">title_str</span>
        <span class="k">if</span> <span class="n">ctx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
            <span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">[:],</span> <span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_show_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">})</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">logvar</span><span class="p">[:],</span> <span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_show_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">})</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">ctx</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu</span><span class="p">[:],</span> <span class="n">logvar</span><span class="p">[:],</span> <span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_show_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">ctx</span>
    
<span class="c1"># could we do a typedispatch to manage the transforms...?</span>
<span class="k">def</span> <span class="nf">VAETargetTupleBlock</span><span class="p">():</span> 
    <span class="k">return</span> <span class="n">TransformBlock</span><span class="p">(</span><span class="n">type_tfms</span><span class="o">=</span><span class="n">VAETargetTuple</span><span class="o">.</span><span class="n">create</span><span class="p">,</span> <span class="n">batch_tfms</span><span class="o">=</span><span class="n">IntToFloatTensor</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">LatentTupleBlock</span><span class="p">():</span> 
    <span class="k">return</span> <span class="n">TransformBlock</span><span class="p">(</span><span class="n">type_tfms</span><span class="o">=</span><span class="n">LatentTuple</span><span class="o">.</span><span class="n">create</span><span class="p">,</span> <span class="n">batch_tfms</span><span class="o">=</span><span class="n">noop</span><span class="p">)</span>
    

<span class="c1"># class TensorPoint(TensorBase):</span>
<span class="c1">#     &quot;Basic type for points in an image&quot;</span>
<span class="c1">#     _show_args = dict(s=10, marker=&#39;.&#39;, c=&#39;r&#39;)</span>

<span class="c1">#     @classmethod</span>
<span class="c1">#     def create(cls, t, img_size=None)-&gt;None:</span>
<span class="c1">#         &quot;Convert an array or a list of points `t` to a `Tensor`&quot;</span>
<span class="c1">#         return cls(tensor(t).view(-1, 2).float(), img_size=img_size)</span>

<span class="c1">#     def show(self, ctx=None, **kwargs):</span>
<span class="c1">#         if &#39;figsize&#39; in kwargs: del kwargs[&#39;figsize&#39;]</span>
<span class="c1">#         x = self.view(-1,2)</span>
<span class="c1">#         ctx.scatter(x[:, 0], x[:, 1], **{**self._show_args, **kwargs})</span>
<span class="c1">#         return ctx</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="o">.</span><span class="mi">2</span>
<span class="n">im_size</span> <span class="o">=</span> <span class="n">IMG_SIZE</span>
<span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">5</span>        
<span class="n">nfs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="o">*</span><span class="n">n_blocks</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> 
<span class="n">nfs</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
<span class="c1"># decoder = nn.Sequential(</span>
<span class="c1">#             nn.Linear(latent_size, 16),</span>
<span class="c1">#             UnFlatten(4),</span>
<span class="c1">#             ResBlock(1, 3, 4, act_cls=Mish),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, 4, 8, act_cls=Mish),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, 8, 16, act_cls=Mish),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             nn.Conv2d(16, 1, 3),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             #nn.AdaptiveAvgPool2d((3,im_size, im_size)) </span>
<span class="c1"># )</span>





<span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">out_range</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">tst</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">),</span> <span class="c1">#nn.Linear(latent_dim, 16)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">im_size</span><span class="o">*</span><span class="n">n_blocks</span><span class="o">*</span><span class="n">n_blocks</span><span class="p">),</span> <span class="c1">#nn.Linear(latent_dim, 16)</span>
            <span class="n">ResizeBatch</span><span class="p">(</span><span class="n">im_size</span><span class="p">,</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_blocks</span><span class="p">),</span><span class="c1">#UnFlatten(n_blocks), #4</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#ResBlock(1, 1, 4, act_cls=Mish),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#RResBlock(1, 4, 8, act_cls=Mish),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#ResBlock(1, 8, 16, act_cls=Mish),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#nn.Conv2d(16, 1, 3),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#nn.Conv2d(16, 1, 3),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#nn.Conv2d(16, 1, 3),</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="c1">#nn.Upsample(scale_factor=2),            #</span>
            <span class="c1">#nn.AdaptiveAvgPool2d((3,im_size, im_size)),</span>
            <span class="n">SigmoidRange</span><span class="p">(</span><span class="o">*</span><span class="n">out_range</span><span class="p">),</span> <span class="c1">#nn.Sigmoid()</span>
<span class="p">)</span>
<span class="n">tst</span><span class="p">,</span><span class="n">nfs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span><span class="o">=</span>    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span><span class="n">latent_dim</span><span class="p">))</span>
<span class="c1">#last_size = model_sizes(tst ) #[-1][1]</span>
<span class="c1">#num_features_model(tst)</span>
<span class="c1">#last_size</span>
<span class="c1">#nfs</span>
<span class="n">tst</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">nfs</span>
<span class="c1">#last_size</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">Flatten</span><span class="p">()</span>
<span class="p">)</span>
<span class="c1"># torch.Size([32, 1, 28, 28])</span>
<span class="c1"># torch.Size([32, 16, 28, 28])</span>
<span class="c1"># torch.Size([32, 16, 14, 14])</span>
<span class="c1"># torch.Size([32, 4, 14, 14])</span>
<span class="c1"># torch.Size([32, 4, 7, 7])</span>
<span class="c1"># torch.Size([32, 196])</span>

<span class="n">latent_size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span><span class="c1">#  1-&gt;3</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">)</span> <span class="c1"># 16-&gt;400</span>
        <span class="p">)</span>
<span class="c1">#  torch.Size([32, 1, 28, 28])</span>
<span class="c1"># torch.Size([32, 5, 14, 14])</span>
<span class="c1"># torch.Size([32, 5, 7, 7])</span>
<span class="c1"># torch.Size([32, 1, 4, 4])</span>
<span class="c1"># torch.Size([32, 16])</span>
<span class="c1"># torch.Size([32, 4])       </span>
<span class="n">inp</span><span class="o">=</span>    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">160</span><span class="p">,</span><span class="mi">160</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">8</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">enc</span><span class="p">[:</span><span class="n">ii</span><span class="p">](</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">enc</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dropout</span><span class="o">=</span><span class="mi">0</span>
<span class="n">dec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_size</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
            <span class="n">UnFlatten</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#4-&gt;5</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="c1">#1-&gt;3</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

<span class="c1"># torch.Size([32, 4])</span>
<span class="c1"># torch.Size([32, 16])</span>
<span class="c1"># torch.Size([32, 1, 4, 4])</span>
<span class="c1"># torch.Size([32, 4, 4, 4])</span>
<span class="c1"># torch.Size([32, 4, 8, 8])</span>
<span class="c1"># torch.Size([32, 8, 8, 8])</span>
<span class="c1"># torch.Size([32, 8, 16, 16])</span>
<span class="c1"># torch.Size([32, 16, 16, 16])</span>
<span class="c1"># torch.Size([32, 16, 32, 32])</span>
<span class="c1"># torch.Size([32, 1, 30, 30])</span>
<span class="c1"># torch.Size([32, 1, 28, 28])</span>


<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">12</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">dec</span><span class="p">[:</span><span class="n">ii</span><span class="p">](</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">BASE</span> <span class="o">=</span> <span class="n">im_size</span><span class="o">//</span><span class="mi">2</span><span class="o">**</span><span class="mi">5</span>        
<span class="n">nfs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">+</span><span class="p">[(</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="n">BASE</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">)]</span> 
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nfs</span><span class="p">)</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">2048</span>

<span class="n">BASE</span> <span class="o">=</span> <span class="n">im_size</span><span class="o">//</span><span class="mi">2</span><span class="o">**</span><span class="mi">5</span>
        <span class="c1"># encoder</span>
<span class="n">in_dim</span> <span class="o">=</span> <span class="n">nfs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">BASE</span><span class="o">**</span><span class="mi">2</span> 
        
<span class="n">modules</span> <span class="o">=</span>  <span class="p">[</span><span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> 
                          <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">)</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>    
<span class="c1"># enc =  nn.Sequential(</span>
<span class="c1">#                 ConvLayer(nfs[0],nfs[1],ks=5,stride=2,padding=2),</span>
<span class="c1">#                 ConvLayer(nfs[1],nfs[2],ks=5,stride=2,padding=2),</span>
<span class="c1">#                 ConvLayer(nfs[2],nfs[3],ks=5,stride=2,padding=2),</span>
<span class="c1">#                 ConvLayer(nfs[3],nfs[4],ks=5,stride=2,padding=2),</span>
<span class="c1">#                 ConvLayer(nfs[4],nfs[5],ks=5,stride=2,padding=2),</span>
<span class="c1">#                 Flatten(),</span>
<span class="c1">#                 LinBnDrop(in_dim,hidden_dim,bn=True,p=0.0,act=nn.ReLU(),lin_first=True)</span>
<span class="c1">#             )</span>

<span class="n">enc</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">,</span>
                <span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">LinBnDrop</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">bn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">act</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span><span class="n">lin_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">)</span>

<span class="n">nfs</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">nfs</span><span class="p">)</span>
<span class="c1">#last_size = model_sizes(enc, size=(28,28))[-1][1]</span>



    
<span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">enc</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">z_dim</span><span class="p">))</span>
        
<span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">z_dim</span><span class="p">,</span> <span class="n">im_size</span><span class="o">*</span><span class="n">n_blocks</span><span class="o">*</span><span class="n">n_blocks</span><span class="p">),</span>
            <span class="n">ResizeBatch</span><span class="p">(</span><span class="n">im_size</span><span class="p">,</span><span class="n">n_blocks</span><span class="p">,</span><span class="n">n_blocks</span><span class="p">),</span><span class="c1">#UnFlatten(n_blocks), #4</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">nfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="c1">#nn.Dropout2d(dropout),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
<span class="c1">#last_size</span>

<span class="c1">#             nn.Linear(latent_dim,hidden_dim), #nn.Linear(latent_dim, 16)</span>
<span class="c1">#             nn.Linear(hidden_dim,im_size*n_blocks*n_blocks), #nn.Linear(latent_dim, 16)</span>
<span class="c1">#             ResizeBatch(im_size,n_blocks,n_blocks),#UnFlatten(n_blocks), #4</span>
<span class="c1">#             ResBlock(1, nfs[0], nfs[1], act_cls=Mish), #ResBlock(1, 1, 4, act_cls=Mish),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, nfs[1], nfs[2], act_cls=Mish), #RResBlock(1, 4, 8, act_cls=Mish),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, nfs[2], nfs[3], act_cls=Mish), #ResBlock(1, 8, 16, act_cls=Mish),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, nfs[3], nfs[4], act_cls=Mish), #nn.Conv2d(16, 1, 3),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, nfs[4], nfs[5], act_cls=Mish), #nn.Conv2d(16, 1, 3),</span>
<span class="c1">#             nn.Dropout2d(dropout),</span>
<span class="c1">#             nn.Upsample(scale_factor=2),</span>
<span class="c1">#             ResBlock(1, nfs[5], nfs[6], act_cls=Mish), #nn.Conv2d(16, 1, 3),</span>

            

<span class="n">inp</span><span class="o">=</span>    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">160</span><span class="p">,</span><span class="mi">160</span><span class="p">))</span>

<span class="c1">#encoder[:1](inp).shape</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">enc</span><span class="p">[:</span><span class="n">ii</span><span class="p">](</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">14</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">decoder</span><span class="p">[:</span><span class="n">ii</span><span class="p">](</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">UnFlatten</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MMD_VAE</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">):</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_size</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
            <span class="n">UnFlatten</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
        
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">latent</span><span class="p">),</span> <span class="n">latent</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>    
<span class="c1">#decoder</span>
<span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">5</span>        
<span class="n">nfs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="o">**</span><span class="n">i</span><span class="o">*</span><span class="n">n_blocks</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_blocks</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> 
<span class="n">nfs</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nfs</span><span class="p">)</span>


<span class="n">tst</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="c1">#nn.Linear(latent_dim, 16)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span><span class="n">im_size</span><span class="o">*</span><span class="n">n_blocks</span><span class="o">*</span><span class="n">n_blocks</span><span class="p">)</span> <span class="c1">#nn.Linear(latent_dim, 16)</span>
            <span class="n">UnFlatten</span><span class="p">(</span><span class="n">n_blocks</span><span class="p">),</span> <span class="c1">#4</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#ResBlock(1, 1, 4, act_cls=Mish),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#RResBlock(1, 4, 8, act_cls=Mish),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#ResBlock(1, 8, 16, act_cls=Mish),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">ResBlock</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">nfs</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">act_cls</span><span class="o">=</span><span class="n">Mish</span><span class="p">),</span> <span class="c1">#nn.Conv2d(16, 1, 3),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="n">im_size</span><span class="p">,</span> <span class="n">im_size</span><span class="p">)),</span>
            <span class="n">SigmoidRange</span><span class="p">(</span><span class="o">*</span><span class="n">out_range</span><span class="p">)</span><span class="c1">#nn.Sigmoid()</span>

    
                                         <span class="o">*</span><span class="n">modules</span><span class="p">,</span>
                                      <span class="n">ConvLayer</span><span class="p">(</span><span class="n">nfs</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span><span class="n">nfs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                                <span class="n">ks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1">#act_cls=nn.Sigmoid) )</span>
                                                <span class="n">act_cls</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">SigmoidRange</span><span class="p">,</span> <span class="o">*</span><span class="n">out_range</span><span class="p">)))</span>
    
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="o">=</span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">mlr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">lr1</span><span class="o">+</span><span class="n">lr2</span><span class="p">)</span>
<span class="c1">#geometric mean</span>
<span class="n">gmlr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">])</span><span class="o">.</span><span class="n">log</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">lr1</span><span class="p">,</span><span class="n">lr2</span><span class="p">,</span><span class="n">mlr</span><span class="p">,</span><span class="n">gmlr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1">#learn.fit_flat_cos(n_epoch) #, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr1</span><span class="p">,</span> <span class="n">div_final</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">pct_start</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1">#learn.fit_one_cycle(n_epoch) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">40</span>
<span class="c1">#learn.unfreeze()</span>
<span class="c1">#learn.fit_flat_cos(n_epoch, lr=1e-3, div_final=1e6, pct_start=0.2)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_flat_cos</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr1</span><span class="p">,</span> <span class="n">div_final</span><span class="o">=</span><span class="mf">1e6</span><span class="p">,</span> <span class="n">pct_start</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="c1">#learn.fit_flat_cos(n_epoch, lr=1e-3, div_final=1e5, pct_start=0.5)</span>
<span class="c1">#learn.fit_one_cycle(n_epoch) #, lr_max= base_lr)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MMDVae-</span><span class="si">{</span><span class="s1">&#39;bmean&#39;</span> <span class="k">if</span> <span class="n">batchmean</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span><span class="si">}{</span><span class="s1">&#39;l1&#39;</span> <span class="k">if</span> <span class="n">useL1</span> <span class="k">else</span> <span class="s1">&#39;l2&#39;</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;frozen</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">-alpha</span><span class="si">{</span><span class="n">alpha</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">_%H.%M.%S&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">.pkl&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">=</span><span class="mi">1</span>
<span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_encoder</span><span class="p">(</span><span class="n">nfs</span><span class="p">,</span><span class="n">ks</span><span class="p">,</span><span class="n">conv</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">,</span><span class="n">bn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span><span class="n">act_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    constructor for generic convolutional encoder </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nfs</span><span class="p">)</span>
    <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">ConvBnRelu</span><span class="p">(</span><span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">ks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                            <span class="n">conv</span> <span class="o">=</span> <span class="n">conv</span><span class="p">,</span><span class="n">bn</span><span class="o">=</span><span class="n">bn</span><span class="p">,</span><span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="n">ks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span><span class="mi">2</span> <span class="p">),</span>
                                 <span class="n">Downsample</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">filt_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>        
    <span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layers</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">convs</span>

<span class="k">def</span> <span class="nf">create_encoder_denseblock</span><span class="p">(</span><span class="n">n_dense</span><span class="p">,</span><span class="n">c_start</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    constructor for resnet with dense blocks  (?) </span>

<span class="sd">    n_dense&quot;: 3,</span>
<span class="sd">    &quot;c_start&quot;: 4</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">first_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">ConvBnRelu</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">c_start</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span>
                                <span class="n">ResBlock</span><span class="p">(</span><span class="n">c_start</span><span class="p">),</span>
                                <span class="n">Downsample</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">filt_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">first_layer</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">DenseBlock</span><span class="p">(</span><span class="n">c_start</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">c</span><span class="p">)),</span>
            <span class="n">Downsample</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="n">c_start</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="p">(</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span><span class="n">filt_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dense</span><span class="p">)</span>
    <span class="p">]</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">create_decoder</span><span class="p">(</span><span class="n">nfs</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">conv</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">act_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CURR VALUES:</span>
<span class="sd">    &quot;nfs&quot;:[66,3*32,3*16,3*8,3*4,3*2,3,1,3],</span>
<span class="sd">    &quot;ks&quot;: [ 3, 1, 3,1,3,1,3,1],   </span>
<span class="sd">    &quot;size&quot;: IMG_SIZE </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nfs</span><span class="p">)</span>
    
    <span class="c1"># We add two channels to the first layer to include x and y channels</span>
    <span class="n">first_layer</span> <span class="o">=</span> <span class="n">ConvBnRelu</span><span class="p">(</span><span class="n">nfs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="c1">#input size </span>
                             <span class="n">nfs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="c1"># output size</span>
                             <span class="n">conv</span> <span class="o">=</span> <span class="n">PointwiseConv</span><span class="p">,</span>
                             <span class="n">bn</span><span class="o">=</span><span class="n">bn</span><span class="p">,</span>
                             <span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)</span>

    <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">first_layer</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">ConvBnRelu</span><span class="p">(</span><span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">nfs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">ks</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                              <span class="n">padding</span> <span class="o">=</span> <span class="n">ks</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span><span class="n">conv</span> <span class="o">=</span> <span class="n">conv</span><span class="p">,</span><span class="n">bn</span><span class="o">=</span><span class="n">bn</span><span class="p">,</span><span class="n">act_fn</span><span class="o">=</span><span class="n">act_fn</span><span class="p">)</span>
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>        
    <span class="n">dec_convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layers</span><span class="p">)</span>
    
    <span class="n">dec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">SpatialDecoder2D</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="n">dec_convs</span><span class="p">)</span>
    <span class="c1">#SigmoidRange(*y_range)</span>
    <span class="k">return</span> <span class="n">dec</span>

<span class="k">def</span> <span class="nf">decoder_simple</span><span class="p">(</span><span class="n">y_range</span><span class="o">=</span><span class="n">OUT_RANGE</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="c1">#UpsampleBlock(64),</span>
                         <span class="n">UpsampleBlock</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                         <span class="n">SigmoidRange</span><span class="p">(</span><span class="o">*</span><span class="n">y_range</span><span class="p">)</span>
                        <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

